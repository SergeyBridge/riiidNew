{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curdir /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/2020Riiid\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from time import time, sleep\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(plt.style.available)\n",
    "plt.style.use(\"dark_background\")\n",
    "# plt.style.use(\"seaborn-dark\")\n",
    "import plotly.express as plx\n",
    "import seaborn as sns\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask import compute\n",
    "from dask import delayed\n",
    "\n",
    "import gc\n",
    "\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster)\n",
    "\n",
    "\n",
    "print(f\"curdir {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "train.csv\n",
    "\n",
    "01. row_id: (int64) ID code for the row.\n",
    "02. timestamp: (int64) the time in milliseconds between this user interaction and the first event completion from that user.\n",
    "03. user_id: (int32) ID code for the user.\n",
    "04. content_id: (int16) ID code for the user interaction\n",
    "05. content_type_id: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n",
    "06. task_container_id: (int16) Id code for the batch of questions or lectures.\n",
    "    For example, a user might see three questions in a row before seeing the explanations for any of them.\n",
    "    Those three would all share a task_container_id.\n",
    "07. user_answer: (int8) the user's answer to the question, if any. Read -1 as null, for lectures.\n",
    "08. answered_correctly: (int8) if the user responded correctly. Read -1 as null, for lectures.\n",
    "09. prior_question_elapsed_time: (float32) The average time in milliseconds it took a user to answer each question\n",
    "    in the previous question bundle, ignoring any lectures in between.\n",
    "    Is null for a user's first question bundle or lecture.\n",
    "    Note that the time is the average time a user took to solve each question in the previous bundle.\n",
    "10. prior_question_had_explanation: (bool) Whether or not the user saw an explanation and the correct response(s)\n",
    "    after answering the previous question bundle, ignoring any lectures in between.\n",
    "    The value is shared across a single question bundle, and is null for a user's first question bundle or lecture.\n",
    "    Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.\n",
    "\n",
    "    questions.csv: metadata for the questions posed to users.\n",
    "1. question_id: foreign key for the train/test content_id column, when the content type is question (0).\n",
    "2. bundle_id: code for which questions are served together.\n",
    "3. correct_answer: the answer to the question.\n",
    "    Can be compared with the train user_answer column to check if the user was right.\n",
    "4. part: the relevant section of the TOEIC test.\n",
    "5. tags: one or more detailed tag codes for the question.\n",
    "    The meaning of the tags will not be provided,\n",
    "    but these codes are sufficient for clustering the questions together.\n",
    "\n",
    "     lectures.csv: metadata for the lectures watched by users as they progress in their education.\n",
    "1. lecture_id: foreign key for the train/test content_id column, when the content type is lecture (1).\n",
    "2. part: top level category code for the lecture.\n",
    "3. tag: one tag codes for the lecture.\n",
    "    The meaning of the tags will not be provided,\n",
    "    but these codes are sufficient for clustering the lectures together.\n",
    "4. type_of: brief description of the core purpose of the lecture\n",
    "\n",
    "   example_test_rows.csv Three sample groups of the test set data as it will be delivered by the time-series API. The format is largely the same as train.csv. There are two different columns that mirror what information the AI tutor actually has available at any given time, but with the user interactions grouped together for the sake of API performance rather than strictly showing information for a single user at a time. Some users will appear in the hidden test set that have NOT been presented in the train set, emulating the challenge of quickly adapting to modeling new arrivals to a website.\n",
    "\n",
    "   prior_group_responses (string) provides all of the user_answer entries for previous group\n",
    "    in a string representation of a list in the first row of the group.\n",
    "    All other rows in each group are null.\n",
    "    If you are using Python, you will likely want to call eval on the non-null rows.\n",
    "    Some rows may be null, or empty lists.\n",
    "\n",
    "   prior_group_answers_correct (string) provides all the answered_correctly field for previous group,\n",
    "    with the same format and caveats as prior_group_responses.\n",
    "    Some rows may be null, or empty lists.\n",
    "\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ntrain.csv\\n\\n01. row_id: (int64) ID code for the row.\\n02. timestamp: (int64) the time in milliseconds between this user interaction and the first event completion from that user.\\n03. user_id: (int32) ID code for the user.\\n04. content_id: (int16) ID code for the user interaction\\n05. content_type_id: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\\n06. task_container_id: (int16) Id code for the batch of questions or lectures.\\n    For example, a user might see three questions in a row before seeing the explanations for any of them.\\n    Those three would all share a task_container_id.\\n07. user_answer: (int8) the user's answer to the question, if any. Read -1 as null, for lectures.\\n08. answered_correctly: (int8) if the user responded correctly. Read -1 as null, for lectures.\\n09. prior_question_elapsed_time: (float32) The average time in milliseconds it took a user to answer each question\\n    in the previous question bundle, ignoring any lectures in between.\\n    Is null for a user's first question bundle or lecture.\\n    Note that the time is the average time a user took to solve each question in the previous bundle.\\n10. prior_question_had_explanation: (bool) Whether or not the user saw an explanation and the correct response(s)\\n    after answering the previous question bundle, ignoring any lectures in between.\\n    The value is shared across a single question bundle, and is null for a user's first question bundle or lecture.\\n    Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.\\n\\n    questions.csv: metadata for the questions posed to users.\\n1. question_id: foreign key for the train/test content_id column, when the content type is question (0).\\n2. bundle_id: code for which questions are served together.\\n3. correct_answer: the answer to the question.\\n    Can be compared with the train user_answer column to check if the user was right.\\n4. part: the relevant section of the TOEIC test.\\n5. tags: one or more detailed tag codes for the question.\\n    The meaning of the tags will not be provided,\\n    but these codes are sufficient for clustering the questions together.\\n\\n     lectures.csv: metadata for the lectures watched by users as they progress in their education.\\n1. lecture_id: foreign key for the train/test content_id column, when the content type is lecture (1).\\n2. part: top level category code for the lecture.\\n3. tag: one tag codes for the lecture.\\n    The meaning of the tags will not be provided,\\n    but these codes are sufficient for clustering the lectures together.\\n4. type_of: brief description of the core purpose of the lecture\\n\\n   example_test_rows.csv Three sample groups of the test set data as it will be delivered by the time-series API. The format is largely the same as train.csv. There are two different columns that mirror what information the AI tutor actually has available at any given time, but with the user interactions grouped together for the sake of API performance rather than strictly showing information for a single user at a time. Some users will appear in the hidden test set that have NOT been presented in the train set, emulating the challenge of quickly adapting to modeling new arrivals to a website.\\n\\n   prior_group_responses (string) provides all of the user_answer entries for previous group\\n    in a string representation of a list in the first row of the group.\\n    All other rows in each group are null.\\n    If you are using Python, you will likely want to call eval on the non-null rows.\\n    Some rows may be null, or empty lists.\\n\\n   prior_group_answers_correct (string) provides all the answered_correctly field for previous group,\\n    with the same format and caveats as prior_group_responses.\\n    Some rows may be null, or empty lists.\\n\\n\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalCluster('tcp://127.0.0.1:46451', workers=4, threads=4, memory=16.75 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Client: 'tcp://127.0.0.1:46451' processes=4 threads=4, memory=16.75 GB>",
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:46451</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>4</li>\n  <li><b>Cores: </b>4</li>\n  <li><b>Memory: </b>16.75 GB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)  # start distributed scheduler locally.  Launch dashboard\n",
    "print(cluster)\n",
    "client"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time()\n",
    "    yield\n",
    "\n",
    "    print(f'[{name}] done in {time() - t0:.2f} s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reading SSD feather] done in 3.01 s\n",
      "CPU times: user 2.88 s, sys: 172 ms, total: 3.06 s\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"boolean\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"boolean\"\n",
    "}\n",
    "\n",
    "dask_dtypes = {\n",
    "    \"row_id\": np.int64,\n",
    "    \"timestamp\": np.int64,\n",
    "    \"user_id\": np.int32,\n",
    "    \"content_id\": np.int16,\n",
    "    \"content_type_id\": bool,\n",
    "    \"task_container_id\": np.int16,\n",
    "    \"user_answer\": np.int8,\n",
    "    \"answered_correctly\": np.int8,\n",
    "    \"prior_question_elapsed_time\": np.float32,\n",
    "    # \"prior_question_had_explanation\": bool\n",
    "}\n",
    "\n",
    "# with timer(\"reading SSD feather\"):\n",
    "#     data_pd = pd.read_csv(\"./input/train.csv\", dtype=dtypes, nrows=12.5e6, low_memory=False)\n",
    "    # data_dd = dd.from_pandas(data_pd, chunksize=int(1e4))\n",
    "    # del data_pd\n",
    "    # _ = gc.collect()\n",
    "    # data_pd = pd.read_feather(\"/mnt/data30G/2020riid/riiid_train.feather\")\n",
    "    # train_dd = dd.from_pandas(train, chunksize=int(1e4))\n",
    "    # train_dd = dd.read_csv(\"/mnt/data30G/2020riid/train.csv\",\n",
    "    #                                dtype=dask_dtypes,\n",
    "    #                                assume_missing=True,\n",
    "    #                                low_memory=False,\n",
    "    #                       )\n",
    "\n",
    "\n",
    "    # train = train.loc[:1e5]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_id  timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
      "0       0          0      115        5692            False                  1   \n",
      "1       1      56943      115        5716            False                  2   \n",
      "2       2     118363      115         128            False                  0   \n",
      "3       3     131167      115        7860            False                  3   \n",
      "4       4     137965      115        7922            False                  4   \n",
      "\n",
      "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
      "0            3                   1                          NaN   \n",
      "1            2                   1                      37000.0   \n",
      "2            0                   1                      55000.0   \n",
      "3            0                   1                      19000.0   \n",
      "4            1                   1                      11000.0   \n",
      "\n",
      "   prior_question_had_explanation  \n",
      "0                            <NA>  \n",
      "1                           False  \n",
      "2                           False  \n",
      "3                           False  \n",
      "4                           False  \n"
     ]
    }
   ],
   "source": [
    "data_pd = data_pd[data_pd.answered_correctly != -1]\n",
    "print(data_pd.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"groupby started\")\n",
    "users = data_pd.groupby(\"user_id\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(users) 3824 764\n"
     ]
    }
   ],
   "source": [
    "users_len = len(users)\n",
    "nvalid = int(users_len/5)\n",
    "print(\"len(users)\", users_len, nvalid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users.tail(nvalid) started\n",
      "CPU times: user 280 ms, sys: 17.8 ms, total: 298 ms\n",
      "Wall time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"users.tail(nvalid) started\")\n",
    "valid_pd = users.tail(nvalid)\n",
    "valid_pd.reset_index().to_feather(\"/mnt/data30G/2020riid/valid_small.feather\")\n",
    "valid_mean = valid_pd.answered_correctly.dropna().values.mean()\n",
    "\n",
    "del valid_pd\n",
    "_ = gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users.head(users_len-nvalid) started\n",
      "train_pd (886259, 10)\n",
      "CPU times: user 340 ms, sys: 34.8 ms, total: 375 ms\n",
      "Wall time: 374 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"users.head(users_len-nvalid) started\")\n",
    "train_pd = users.head(users_len-nvalid)\n",
    "train_pd.reset_index().to_feather(\"/mnt/data30G/2020riid/train_small.feather\")\n",
    "train_mean = train_pd.answered_correctly.dropna().values.mean()\n",
    "print(\"train_pd\", train_pd.shape)\n",
    "\n",
    "del train_pd\n",
    "_ = gc.collect()\n",
    "\n",
    "# print(\"valid_pd\", valid_pd.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trainmean validmean\n",
      "0.6474281220275337 0.63636007614533\n"
     ]
    }
   ],
   "source": [
    "print(\" trainmean validmean\")\n",
    "print(train_mean, valid_mean)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with timer(\"types SSD\"):\n",
    "#     for col, type_ in dask_dtypes.items():\n",
    "#         print(col, train_dd[col].dtype())\n",
    "#         # train[col] = train[col].astype(type_)\n",
    "#         train_dd[col] = delayed(train_dd[col].astype(type_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# train_dd = train_dd.loc[:10000]\n",
    "print(\"1 train_dd.head()\")\n",
    "\n",
    "# train_dd.head()\n",
    "print(type(train_dd))\n",
    "train_dd.shape[0].compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if \"row_id\" in train_dd.columns:\n",
    "    # train.set_index(\"row_id\", inplace=True)\n",
    "    train_dd = train_dd.set_index(\"row_id\")\n",
    "    # res = train_dd.mean()\n",
    "    # res = delayed(train_dd.mean)()\n",
    "# res_delayed = res.compute()\n",
    "print(\"res = train_dd.mean()\")\n",
    "# print(res_delayed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "res_delayed = delayed(train_dd.mean)()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_delayed.visualize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with ProgressBar():\n",
    "    out = res_delayed.compute()\n",
    "\n",
    "    print(f\" out res_delayed = \\n {out}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_delayed.visualize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_dd[\"attempt\"] = -1\n",
    "\n",
    "print(f\" train_dd.head() 2 = \")\n",
    "train_dd.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dd.count().compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(train_dd) - train_dd.count().compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_dd.shape[0].compute(), train_dd.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(train_dd.user_id.compute()).nunique()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"max\", train_dd.user_id.compute().value_counts().max())\n",
    "print(\"mean\", train_dd.user_id.compute().value_counts().mean())\n",
    "print(\"median\", train_dd.user_id.compute().value_counts().quantile(.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "max, mean, median = compute(\n",
    "    train_dd.user_id.value_counts().max(),\n",
    "    train_dd.user_id.value_counts().mean(),\n",
    "    train_dd.user_id.value_counts().quantile(.5)\n",
    ")\n",
    "print(max, mean, median)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_user_quantiles(df, plot=False):\n",
    "\n",
    "    quantiles = []\n",
    "    for q in np.arange(start=.4, stop=.8, step=.1):\n",
    "        quantiles.append((q, df.user_id.value_counts().quantile(q=q).compute()))\n",
    "        if plot:\n",
    "            print(f\"quantile {quantiles[-1]}\")\n",
    "            plt.plot(*quantiles[-1], marker=\"o\",  c=\"w\")\n",
    "    return quantiles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dd.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# total = train_dd.user_id.nunique()\n",
    "groups = train_dd.groupby(by=\"user_id\")\n",
    "# total = len(groups.size())\n",
    "# print(\"total\", total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "def print_count(group):\n",
    "    print(\"print 1 from print_count\")\n",
    "\n",
    "groups_apply = groups.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_apply.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iter = groups\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "content_id_sum = groups.content_id.sum()\n",
    "\n",
    "print(\"content_id_sum.compute()\")\n",
    "content_id_sum.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "agg = groups.aggregate(['sum', 'mean', 'max', 'min', list]).compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agg.loc[115, \"timestamp\"][\"sum\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with timer(\"rolling values\"):\n",
    "    for id, df in tqdm(groups, total=total):\n",
    "        print(\"ok\")\n",
    "        # print(f\"  user_id = {id}  shape = {df.shape[0]} is_monotonic {df.timestamp.is_monotonic}\")\n",
    "        pass\n",
    "        # train_dd.loc[df.index, \"attempt\"] = range(1, df.shape[0]+1)\n",
    "\n",
    "        # quantiles = get_user_quantiles(df=df)\n",
    "        #\n",
    "        # for quantile, val in quantiles:\n",
    "        #     train_dd.loc[df.index, f\"q{quantile}_None\"] = df.timestamp.rolling(\n",
    "        #         int(val),\n",
    "        #         min_periods=1,\n",
    "        #         win_type=None,\n",
    "        #     ).quantile(quantile)\n",
    "        #\n",
    "        #     train_dd.loc[df.index, f\"q{quantile}_gauss\"] = df.timestamp.rolling(\n",
    "        #         int(val),\n",
    "        #         min_periods=1,\n",
    "        #         win_type=\"gaussian\",\n",
    "        #     ).mean(std=3)\n",
    "        #\n",
    "        #     train_dd.loc[df.index, f\"q{quantile}_exp\"] = df.timestamp.rolling(\n",
    "        #         int(val),\n",
    "        #         min_periods=1,\n",
    "        #         win_type=\"exponential\",\n",
    "        #     ).sum(tau=3)\n",
    "\n",
    "# train_dd = train_dd.compute()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_shuffled = train.sample()\n",
    "print(\"train.shape\", train.shape)\n",
    "train.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submit_example = pd.read_csv(\"./input/example_sample_submission.csv\", )\n",
    "test = pd.read_csv(\"./input/example_test.csv\")\n",
    "lectures = pd.read_csv(\"./input/lectures.csv\")\n",
    "questions = pd.read_csv(\"./input/questions.csv\")\n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"submit_example.shape\", submit_example.shape[0])\n",
    "submit_example.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"test.shape\", test.shape)\n",
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"lectures.shape\", lectures.shape)\n",
    "lectures.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set(train.columns).symmetric_difference(set(test.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set(test.columns) - set(train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set(train.columns) - set(test.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# train_dt = dt.fread(\"./input/train.csv\")\n",
    "# print(\"train_dt.head()\")\n",
    "# train_dt.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"questions.shape\", questions.shape)\n",
    "questions.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bundle_ids = questions.value_counts(subset=[\"bundle_id\"])\n",
    "print(bundle_ids)\n",
    "plt.hist(x=bundle_ids, bins=10);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions.value_counts(subset=[\"correct_answer\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions.value_counts(subset=[\"part\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions.tags = questions.tags.astype(str).apply([str.strip, str.split])\n",
    "questions.tags[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ll = train_dt.shape[0]\n",
    "#\n",
    "# uniques = dt.unique(train_dt[\"user_id\"]).shape[0]\n",
    "# print(ll)\n",
    "# print(uniques)\n",
    "# print(ll/uniques)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "value_counts = train.user_id.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "value_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(value_counts);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}