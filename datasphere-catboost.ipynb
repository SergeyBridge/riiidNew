{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python"},"papermill":{"duration":392.708184,"end_time":"2020-11-23T16:52:33.291774","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-11-23T16:46:00.583590","version":"2.1.0"},"notebookId":"3476dacc-b067-43bd-96d6-3dd90b58e4f1"},"cells":[{"cell_type":"code","source":"#!M\n# !pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n# %pip install --upgrade pip\n# %pip install -r /home/jupyter/work/resources/riiidNew/requirements.txt --upgrade \nprint(\"ok\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":30.191831,"end_time":"2020-11-23T16:46:34.873724","exception":false,"start_time":"2020-11-23T16:46:04.681893","status":"completed"},"tags":[],"cellId":"r4gbiatk8h938d934p4aip","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Necessary packages","metadata":{"papermill":{"duration":0.018571,"end_time":"2020-11-23T16:46:34.912747","exception":false,"start_time":"2020-11-23T16:46:34.894176","status":"completed"},"tags":[],"cellId":"pz3uk46r8c9ejefq2dp3m"}},{"cell_type":"code","source":"#!M\nimport numpy as np\nimport pandas as pd\nimport pyarrow\nfrom collections import defaultdict\n# import datatable as dt\nimport lightgbm as lgb\n\nfrom catboost.utils import get_gpu_device_count\nfrom catboost import CatBoostClassifier, Pool\n\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n# import riiideducation\nimport torch\nimport pickle\nimport gc\nfrom pathlib import Path\n\n# Error handling, ignore all\nnp.seterr(divide = 'ignore', invalid = 'ignore')\n\nprint(f\"pyarrow {pyarrow.__version__}\")\nprint(f\"curdir {Path.cwd()}\")","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":2.195965,"end_time":"2020-11-23T16:46:37.127434","exception":false,"start_time":"2020-11-23T16:46:34.931469","status":"completed"},"tags":[],"cellId":"t3n208wi88qtuu9cu40m","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"papermill":{"duration":0.019813,"end_time":"2020-11-23T16:46:37.168146","exception":false,"start_time":"2020-11-23T16:46:37.148333","status":"completed"},"tags":[],"cellId":"anxc5qpofibelpn72czs7"}},{"cell_type":"markdown","source":"* Data config","metadata":{"papermill":{"duration":0.019374,"end_time":"2020-11-23T16:46:37.206927","exception":false,"start_time":"2020-11-23T16:46:37.187553","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"9z1ri5b2lwike4azllkjpp"}},{"cell_type":"code","source":"dtypes = {\n    'row_id': 'int64',\n    'timestamp': 'int64',\n    'user_id': 'int32', \n    'content_id': 'int16', \n    'content_type_id': 'int8',\n    'task_container_id': 'int16',\n    'answered_correctly': 'int8', \n    'prior_question_elapsed_time': 'float32', \n    'prior_question_had_explanation': 'bool',\n    'user_answer': 'int8',\n}\n\ntarget = 'answered_correctly'","metadata":{"papermill":{"duration":0.026993,"end_time":"2020-11-23T16:46:37.253096","exception":false,"start_time":"2020-11-23T16:46:37.226103","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"4dtjg452dd7ekvta7bvj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Import data","metadata":{"papermill":{"duration":0.018939,"end_time":"2020-11-23T16:46:37.290855","exception":false,"start_time":"2020-11-23T16:46:37.271916","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"3a2ug3cpyyucna2e9lpxs"}},{"cell_type":"code","source":"%%time\n#!M\n\nhomedir = Path.home()\nprint(str(homedir))\nif str(homedir) == \"/home/sergey\":   # Home computer\n    kaggle_path = \"kaggle_tmp/\"\n    questions_df = pd.read_csv('/mnt/data30G/2020riid/questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n    # train_df = dt.fread('../input/riiid-test-answer-prediction/train.csv', columns = set(dtypes.keys())).to_pandas()\n    # train_df = dt.fread('/mnt/data30G/2020riid/train.csv', columns = set(dtypes.keys())).to_pandas()\n    test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train_1e5.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid.feather\", columns=dtypes.keys())\n\nelif str(homedir) == \"/root\":   # Datasphere\n    \n    path = Path.cwd()/\"riiidNew\"/\"data\"\n    kaggle_path = Path.cwd()/\"riiidNew\"/\"kaggle/\"\n    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n#     train_df = pd.read_feather(path/\"cv1_train_1e5.feather\", columns=dtypes.keys())\n#     test_df = pd.read_feather(path/\"cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(path/\"data/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # train_df = pd.read_feather(path/\"cv1_train.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(path/\"cv1_valid.feather\", columns=dtypes.keys())\n    train_df = pd.read_pickle(path/\"cv1_train.pickle.zip\").astype(dtypes, errors=\"ignore\")\n    # train_df = train_df.iloc[:int(1e6)]\n    test_df = pd.read_pickle(path/\"cv1_valid.pickle.zip\").astype(dtypes, errors=\"ignore\")\n    # test_df = test_df.iloc[:int(1e4)]\n\nprint(f\"train_df shape = {train_dfn_df.shape})","metadata":{"papermill":{"duration":65.145462,"end_time":"2020-11-23T16:47:42.455648","exception":false,"start_time":"2020-11-23T16:46:37.310186","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"67ntodpzk98fzmgeq6pe79","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Information of the training dataset","metadata":{"papermill":{"duration":0.020594,"end_time":"2020-11-23T16:47:42.496580","exception":false,"start_time":"2020-11-23T16:47:42.475986","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"vk8q857fkbl0ou00kw2wqoe"}},{"cell_type":"code","source":"#!M\nsep = '*' * 50\nprint(f'Training dataset detailed information \\n{sep}')\nprint(f'Columns: {train_df.columns} \\n{sep}')\nprint(f'Shape: {train_df.shape} \\n{sep}')\nprint(f'NA values in each column: {sum(train_df.isna().sum())} \\n{sep}')\n","metadata":{"papermill":{"duration":11.548951,"end_time":"2020-11-23T16:47:54.068264","exception":false,"start_time":"2020-11-23T16:47:42.519313","status":"completed"},"tags":[],"cellId":"x4nexxr3kgd9p8ff3m8it","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!M\ndef prep_data(df, questions_df=questions_df):\n    # Exclude lectures\n    df = df[df[target] != -1].reset_index(drop = True, inplace = False)\n    # Fill NaN values in the 'prior_question_had_explanation' columns\n    df['prior_question_had_explanation'].fillna(False, inplace = True)\n    # Set type\n    df = df.astype(dtypes)\n    \n    # Answer for the previous questions of users\n    df['lag'] = df.groupby('user_id')[target].shift()\n    # For each user (groupby('user_id')), compute the cummulative number of correct answers and number answers in general\n    groupby = df.groupby('user_id')['lag']\n    cum = groupby.agg(['cumsum', 'cumcount'])\n\n    # User correctness (measure the users' learning progress)\n    df['user_correctness'] = cum['cumsum'] / cum['cumcount']\n    # Drop the 'lag' feature\n    df.drop(columns = ['lag'], inplace = True)\n    df.head()    \n    \n    # Overall correctness of users\n    user_agg = df.groupby('user_id')[target].agg(['sum', 'count'])\n    # Overall difficulty of questions\n    content_agg = df.groupby('content_id')[target].agg(['sum', 'count'])    \n\n    # Take only 24 last observations of each user\n    df = df.groupby('user_id').tail(24).reset_index(drop = True)\n    \n    df = pd.merge(df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    df.drop(columns = ['question_id'], inplace = True)\n\n    # How many questions have been answered in each content ID?\n    df['content_count'] = df['content_id'].map(content_agg['count']).astype('int32')\n    # How hard are questions in each content ID?\n    df['content_id'] = df['content_id'].map(content_agg['sum'] / content_agg['count'])\n    \n    return user_agg, content_agg, df\n    ","metadata":{"pycharm":{"name":"#%%\n"},"cellId":"4wg4fgp8nr8n4akqm0u61","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Extract the validation set","metadata":{"papermill":{"duration":0.021183,"end_time":"2020-11-23T16:48:53.873557","exception":false,"start_time":"2020-11-23T16:48:53.852374","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"hvfpq2wdqaf1hr8xwrqf4q"}},{"cell_type":"code","source":"#!M\ntrain_user_agg, train_content_agg, train_df = prep_data(train_df)\n\nuser_sum_dict = train_user_agg['sum'].astype('int16').to_dict(defaultdict(int))\nuser_count_dict = train_user_agg['count'].astype('int16').to_dict(defaultdict(int))\ncontent_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\ncontent_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\ngc.collect()","metadata":{"papermill":{"duration":1.524016,"end_time":"2020-11-23T16:48:55.418847","exception":false,"start_time":"2020-11-23T16:48:53.894831","status":"completed"},"tags":[],"cellId":"r2n4048i8x8wkxqr1vkg4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n#!M\ntest_user_agg, test_content_agg, test_df = prep_data(test_df)\ngc.collect()","metadata":{"papermill":{"duration":1.524016,"end_time":"2020-11-23T16:48:55.418847","exception":false,"start_time":"2020-11-23T16:48:53.894831","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"m4theb47y267g8ssgpa7u","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ratio is 6/24 = 25%\nvalid_df = train_df.groupby('user_id').tail(6)\ntrain_df.drop(valid_df.index, inplace = True)","metadata":{"papermill":{"duration":3.111291,"end_time":"2020-11-23T16:48:58.928890","exception":false,"start_time":"2020-11-23T16:48:55.817599","status":"completed"},"tags":[],"cellId":"wihq857gcng65klgbn89e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{"papermill":{"duration":0.023143,"end_time":"2020-11-23T16:48:58.975838","exception":false,"start_time":"2020-11-23T16:48:58.952695","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"suwfns3lzdchqhn90tmrsi"}},{"cell_type":"markdown","source":"* Construct data","metadata":{"papermill":{"duration":0.021554,"end_time":"2020-11-23T16:48:59.019149","exception":false,"start_time":"2020-11-23T16:48:58.997595","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"btj0scm1va9c5b8kid5ow"}},{"cell_type":"code","source":"#!L\nfeatures = ['content_id', 'prior_question_elapsed_time', \n            'prior_question_had_explanation', 'user_correctness', \n            'part', 'content_count']\n\nparams = {\n    'loss_function': 'Logloss',\n    'eval_metric': 'AUC',\n\n    'task_type': 'GPU' if get_gpu_device_count() > 0 else 'CPU',\n    # 'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n    'grow_policy': 'Lossguide',\n    'iterations': 10000,\n    'learning_rate': 4e-3,\n    'random_seed': 0,\n    'l2_leaf_reg': 1e-1,\n    'depth': 6,\n    # 'max_leaves': 10,\n    'border_count': 128,\n    'verbose': 50,\n    'od_type': 'Iter',\n    'od_wait': 30,\n}","metadata":{"papermill":{"duration":0.431014,"end_time":"2020-11-23T16:48:59.471718","exception":false,"start_time":"2020-11-23T16:48:59.040704","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"deuvgp09gf4q8shcxcfxeq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n#!M\n# Training and validating data\ntrain_set = Pool(train_df[features], label = train_df[target])\nval_set = Pool(valid_df[features], label = valid_df[target])\n# val_set = Pool(test_df[features], label = test_df[target])","metadata":{"papermill":{"duration":4.226965,"end_time":"2020-11-23T16:49:03.721844","exception":false,"start_time":"2020-11-23T16:48:59.494879","status":"completed"},"tags":[],"cellId":"5w20q7e6r68iplz1whchn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n#!L\n# Model definition\nmodel = CatBoostClassifier(**params)\n\n# Fitting\nmodel.fit(train_set, eval_set = val_set, use_best_model = True)","metadata":{"papermill":{"duration":207.603145,"end_time":"2020-11-23T16:52:31.347675","exception":false,"start_time":"2020-11-23T16:49:03.744530","status":"completed"},"tags":[],"cellId":"plqx8q5gewpdkgl6c91u","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_model(f\"{kaggle_path}catboost.model\")","metadata":{"papermill":{"duration":207.603145,"end_time":"2020-11-23T16:52:31.347675","exception":false,"start_time":"2020-11-23T16:49:03.744530","status":"completed"},"tags":[],"cellId":"ulsca9w9za11n13os38t49","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.051177,"end_time":"2020-11-23T16:52:31.451640","exception":false,"start_time":"2020-11-23T16:52:31.400463","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"ba4wdwyypnjxlgzfd769b9"}},{"cell_type":"code","source":"#!M\nuser_sum_dict = train_user_agg['sum'].astype('int16').to_dict(defaultdict(int))\nuser_count_dict = train_user_agg['count'].astype('int16').to_dict(defaultdict(int))\ncontent_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\ncontent_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n\nfor filename, dic in zip([\"user_sum_dict\", \"user_count_dict\", \"content_sum_dict\", \"content_count_dict\"],\n                         [user_sum_dict, user_count_dict, content_sum_dict, content_count_dict]):\n    with open(f'{kaggle_path}{filename}.pickle', 'wb') as handle:\n        pickle.dump(dic, handle)\n","metadata":{"papermill":{"duration":0.618845,"end_time":"2020-11-23T16:52:32.122494","exception":false,"start_time":"2020-11-23T16:52:31.503649","status":"completed"},"tags":[],"cellId":"7ui7ur3vc7044m7d88w7h2"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()\n","metadata":{"cellId":"t8443l740slicr5x1cuvl"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del train_df\ngc.collect()\n","metadata":{"cellId":"10lykr4g0xjkfq9lik4q3tb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_df.head()","metadata":{"cellId":"5khjipzjrxcyojdlju0z"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# test_df = pd.read_pickle(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.pickle.zip\")\n# test_df = test_df.iloc[:int(1e5)]","metadata":{"cellId":"2u9rdo546tnw42i6zuf969"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nvalidaten_flg = True\nif validaten_flg:\n    from emulator import Iter_Valid\n    iter_test = Iter_Valid(valid_df,max_user=1000)\n    predicted = []\n    def set_predict(df):\n        predicted.append(df)\nelse:\n    import riiideducation\n    env = riiideducation.make_env()\n    iter_test = env.iter_test()\n    set_predict = env.predict","metadata":{"cellId":"6qrpfrl3bhn281e5c5twea"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cumcount = sum([len(df) for df in predicted])\n# count = 0\n# pbar = tqdm(total=cumcount)\n# previous_test_df = None\n# for (current_test, current_prediction_df) in iter_test:\n#     count+=1\n#     if previous_test_df is not None:\n#         answers = eval(current_test[\"prior_group_answers_correct\"].iloc[0])\n#         responses = eval(current_test[\"prior_group_responses\"].iloc[0])\n#         previous_test_df['answered_correctly'] = answers\n#         previous_test_df['user_answer'] = responses\n#         # your feature extraction and model training code here\n#     previous_test_df = current_test.copy()\n#     current_test = current_test[current_test.content_type_id == 0]\n#     # your prediction code here\n#     current_test['answered_correctly'] = model.predict(current_test[features])  # 0.5\n#     set_predict(current_test.loc[:,['row_id', 'answered_correctly']])\n#     pbar.update(len(current_test))\n# print(f\"count {count} {len(predicted)}\")","metadata":{"papermill":{"duration":466.435487,"end_time":"2020-11-13T14:06:20.068150","exception":false,"start_time":"2020-11-13T13:58:33.632663","status":"completed"},"tags":[],"cellId":"hkq3ce6f9zot3ymxi9x1s"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_df","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"yzork8xo17phg263eq5lvj"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nprior_test_df = None\nfor (test_df, sample_prediction_df) in iter_test:\n    if prior_test_df is not None:\n        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop = True)\n        \n        user_ids = prior_test_df['user_id'].values\n        content_ids = prior_test_df['content_id'].values\n        targets = prior_test_df[target].values\n        \n        for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n            user_sum_dict[user_id] += answered_correctly\n            user_count_dict[user_id] += 1\n            content_sum_dict[content_id] += answered_correctly\n            content_count_dict[content_id] += 1\n\n    prior_test_df = test_df.copy()\n    \n    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n    test_df.drop(labels=\"part\", axis=1, inplace=True)\n    test_df.content_id = test_df.content_id.astype(int)\n    \n    test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')    \n    user_sum = np.zeros(len(test_df), dtype = np.int16)\n    user_count = np.zeros(len(test_df), dtype = np.int16)\n    content_sum = np.zeros(len(test_df), dtype = np.int32)\n    content_count = np.zeros(len(test_df), dtype = np.int32)\n    \n    for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n        user_sum[i] = user_sum_dict[user_id]\n        user_count[i] = user_count_dict[user_id]\n        content_sum[i] = content_sum_dict[content_id]\n        content_count[i] = content_count_dict[content_id]\n\n    test_df['user_correctness'] = user_sum / user_count\n    test_df['content_count'] = content_count\n    test_df['content_id'] = content_sum / content_count\n    test_df[target] = model.predict_proba(test_df[features])[:,1]\n    set_predict(test_df[['row_id', target]])\n","metadata":{"papermill":{"duration":0.550421,"end_time":"2020-11-23T16:52:32.842277","exception":false,"start_time":"2020-11-23T16:52:32.291856","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"ikplh5uhkz9cgxru9hxh"},"outputs":[],"execution_count":null}]}