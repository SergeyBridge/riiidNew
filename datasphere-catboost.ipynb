{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python"},"papermill":{"duration":392.708184,"end_time":"2020-11-23T16:52:33.291774","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-11-23T16:46:00.583590","version":"2.1.0"},"notebookId":"ad948183-ff32-4aea-9319-3201ee2851bc"},"cells":[{"cell_type":"code","source":"#!M\n# !pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n# %pip install --upgrade pip\n# %pip install -r /home/jupyter/work/resources/riiidNew/requirements.txt --upgrade\n# %pip install scipy  --ignore-installed scipy --upgrade\nprint(\"ok\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":30.191831,"end_time":"2020-11-23T16:46:34.873724","exception":false,"start_time":"2020-11-23T16:46:04.681893","status":"completed"},"tags":[],"cellId":"r4gbiatk8h938d934p4aip","trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#!L\n# if str(Path.home()) == \"/root\":  # DATASPHERE\nimport sys\nimport gc\nfrom pathlib import Path\nsys.path.append(str(Path.cwd()/'riiidNew'))\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport pyarrow\nfrom collections import defaultdict\nfrom catboost import CatBoostClassifier, Pool\nfrom preprocess import preprocess_train_data\nfrom catboost_bayesian_search import bayesian_catboost_searchCV, param_adjust_dtypes\nimport config\n\n# Error handling, ignore all\nnp.seterr(divide = 'ignore', invalid = 'ignore')\n\n\nif str(Path.home()) == \"/home/sergey\":   # Home computer\n    kaggle_path = Path.cwd()/\"kaggle_tmp/\"\n    questions_df = pd.read_csv('/mnt/data30G/2020riiid/questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n    test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train_1e5.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid.feather\", columns=dtypes.keys())\n\nelif str(Path.home()) == \"/root\":   # DATASPHERE\n    \n    path = Path.cwd()/\"riiidNew\"/\"data1\"\n    kaggle_path = Path.cwd()/\"riiidNew\"/\"kaggle\"\n    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n    # train_df = pd.read_feather(path/\"train.feather\", columns=config.dtypes.keys())\n    # train_df = pd.read_feather(path/\"train_5e6.feather\", columns=config.dtypes.keys())\n    train_df = pd.read_feather(path/\"train_1e5.feather\", columns=config.dtypes.keys())\n    # train_df = pd.read_pickle(path/'cv2_train.pickle.zip').astype(config.dtypes, errors=\"ignore\")\n    # test_df = pd.read_pickle(path/\"cv2_valid.pickle.zip\").astype(config.dtypes, errors=\"ignore\")\n\n# # print(f\"train_df shape = {train_df.shape}\")\n\n# # Preprocess for CV\n# train_user_agg, train_content_agg, train_df = preprocess_train_data(train_df, questions_df, config.target, config.dtypes)\n# # test_user_agg, test_content_agg, test_df = preprocess_train_data(test_df, questions_df, config.target, config.dtypes)\n# print(\"Preprocess for CV ok\")\n\n# # Training and validating data\n# train_set = Pool(train_df[config.features], label = train_df[config.target], cat_features=config.cat_features)\n# # val_set = Pool(test_df[features], label = test_df[target])\n\n# print(\"optimizer_maxCV ..\")\n# optimizer_maxCV = bayesian_catboost_searchCV(\n#     train_set,\n#     prior_params=config.prior_params,\n#     pds=config.pds, pds_dtypes=config.pds_dtypes,\n#     init_points=5, n_iter=25, verbose=False,\n# )\n# print(\"optimizer_maxCV ..\")\n# print(optimizer_maxCV)\n\n# params = param_adjust_dtypes(config.prior_params, \n#                              config.pds_dtypes, \n#                              optimizer_maxCV[\"params\"])\n# print(\"params\")\n# print(params)\n\n# # pds_fitted = {key: config.pds_dtypes[key](val) for key, val in optimizer_maxCV[\"params\"].items()}\n# # params = prior_params.copy()\n# # params.update(pds_fitted)\n\n# # Ratio is 6/24 = 25%\n# # valid_df = train_df.groupby('user_id').tail(6)\n# # train_df.drop(valid_df.index, inplace = True)\n\n# import pickle\n\n# user_sum_dict = train_user_agg['sum'].astype('int32').to_dict(defaultdict(int))\n# user_count_dict = train_user_agg['count'].astype('int32').to_dict(defaultdict(int))\n# content_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n# content_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n\n# for filename, dic in zip([\"user_sum_dict\", \"user_count_dict\", \"content_sum_dict\", \"content_count_dict\"],\n#                          [user_sum_dict, user_count_dict, content_sum_dict, content_count_dict]):\n#     with open(f'{kaggle_path}/{filename}.pickle', 'wb') as handle:\n#         pickle.dump(dic, handle)\n\n# del train_df, user_sum_dict, train_user_agg, user_count_dict\n# del content_sum_dict, train_content_agg, content_count_dict\n# gc.collect()\n\n# Obtain new trai_df and validation test_df\ntrain_df = pd.read_feather(path/\"cv2_train.feather\", columns=config.dtypes.keys())\n\n# train_df = pd.read_pickle(path/'cv2_train.pickle.zip').astype(config.dtypes, errors=\"ignore\").reset_index()\n# train_df = train_df.iloc[:int(1e5)]\n\ntest_df = pd.read_feather(path/\"cv2_test.feather\", columns=config.dtypes.keys())\n# test_df = pd.read_pickle(path/\"cv2_valid.pickle.zip\").astype(config.dtypes, errors=\"ignore\").reset_index()\n# test_df = test_df.iloc[:int(1e4)]\n\nprint(\"cv2_train.feather, cv2_test.feather ok!\") \n\n# Preprocess for model fitting\ntrain_user_agg, train_content_agg, train_df = preprocess_train_data(train_df, questions_df, config.target, config.dtypes)\ntest_user_agg, test_content_agg, test_df = preprocess_train_data(test_df, questions_df, config.target, config.dtypes)\nprint(\"Preprocess for model fitting ok\")\n\n# Training and validating data\ntrain_set = Pool(train_df[config.features], label = train_df[config.target], cat_features=config.cat_features)\nval_set = Pool(test_df[config.features], label = test_df[config.target], cat_features=config.cat_features)\n\n\n# val_set = Pool(valid_df[features], label = valid_df[target])\n\n# Model definition\nparams = {\n    'loss_function': 'Logloss', \n    'eval_metric': 'AUC', \n    'custom_metric': 'AUC:hints=skip_train~false', \n    'task_type': 'GPU', 'grow_policy': 'Lossguide', \n    'iterations': 2000, 'learning_rate': 0.03, \n    'random_seed': 0, 'bootstrap_type': 'Bayesian', \n    'l2_leaf_reg': 463.75241951019393, \n    'depth': 23, 'max_leaves': 21, \n    'border_count': 163, \n    'verbose': 250, \n    'od_type': 'Iter', \n    'od_wait': 50, \n    'bagging_temperature': 2.055885684521886}\nparams[\"learning_rate\"] = 3e-2\nparams['iterations'] = 20000\n\nmodel = CatBoostClassifier(**params)\n\n# Fitting\nmodel.fit(train_set, eval_set = val_set, use_best_model = True)\nprint(f\"kaggle_path {kaggle_path}\")\n\nmodel.save_model(f\"{kaggle_path/'catboost.model'}\")\n\nprint(\"model.get_best_score()\")\nprint(model.get_best_score())","metadata":{"pycharm":{"name":"#%%\n"},"cellId":"x457vefy7xyyyibor5o8f","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"cv2_train.feather, cv2_test.feather ok!\nPreprocess for model fitting ok\n0:\tlearn: 0.7325786\ttest: 0.7325359\tbest: 0.7325359 (0)\ttotal: 95ms\tremaining: 31m 39s\nbestTest = 0.7401127815\nbestIteration = 193\nShrink model to first 194 iterations.\nkaggle_path /home/jupyter/work/resources/riiidNew/kaggle\nmodel.get_best_score()\n{'learn': {'Logloss': 0.5892835862948705, 'AUC': 0.7472176551818848}, 'validation': {'Logloss': 0.5916236238297615, 'AUC': 0.7401127815246582}}\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:588: UserWarning: The following variables cannot be serialized: train_set, val_set\n  warnings.warn(message)\n"}],"execution_count":3},{"cell_type":"markdown","source":"\n{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'task_type': 'GPU', 'grow_policy': 'Lossguide', 'iterations': 15000, 'learning_rate': 0.01, 'random_seed': 0, 'l2_leaf_reg': 0.1, 'depth': 8, 'border_count': 128, 'verbose': 150, 'od_type': 'Iter', 'od_wait': 50}\nbestTest = 0.7371392846\n\nbestTest = 0.7370638549\nbestTest = 0.7364509702\n","metadata":{"cellId":"nl7v0tm6byjfdfngg11ydh"}},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.051177,"end_time":"2020-11-23T16:52:31.451640","exception":false,"start_time":"2020-11-23T16:52:31.400463","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"ba4wdwyypnjxlgzfd769b9"}},{"cell_type":"code","source":"#!M\nimport pickle\n\nuser_sum_dict = train_user_agg['sum'].astype('int32').to_dict(defaultdict(int))\nuser_count_dict = train_user_agg['count'].astype('int32').to_dict(defaultdict(int))\ncontent_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\ncontent_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n\nfor filename, dic in zip([\"user_sum_dict\", \"user_count_dict\", \"content_sum_dict\", \"content_count_dict\"],\n                         [user_sum_dict, user_count_dict, content_sum_dict, content_count_dict]):\n    with open(f'{kaggle_path}/{filename}.pickle', 'wb') as handle:\n        pickle.dump(dic, handle)\n","metadata":{"papermill":{"duration":0.618845,"end_time":"2020-11-23T16:52:32.122494","exception":false,"start_time":"2020-11-23T16:52:31.503649","status":"completed"},"tags":[],"cellId":"7ui7ur3vc7044m7d88w7h2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()\ndel train_df\ngc.collect()\n","metadata":{"cellId":"t8443l740slicr5x1cuvl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nvalidaten_flg = True\nif validaten_flg:\n    from emulator import Iter_Valid\n    iter_test = Iter_Valid(test_df,max_user=1000)\n    predicted = []\n    def set_predict(df):\n        predicted.append(df)\nelse:\n    import riiideducation\n    env = riiideducation.make_env()\n    iter_test = env.iter_test()\n    set_predict = env.predict","metadata":{"cellId":"6qrpfrl3bhn281e5c5twea","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cumcount = sum([len(df) for df in predicted])\n# count = 0\n# pbar = tqdm(total=cumcount)\n# previous_test_df = None\n# for (current_test, current_prediction_df) in iter_test:\n#     count+=1\n#     if previous_test_df is not None:\n#         answers = eval(current_test[\"prior_group_answers_correct\"].iloc[0])\n#         responses = eval(current_test[\"prior_group_responses\"].iloc[0])\n#         previous_test_df['answered_correctly'] = answers\n#         previous_test_df['user_answer'] = responses\n#         # your feature extraction and model training code here\n#     previous_test_df = current_test.copy()\n#     current_test = current_test[current_test.content_type_id == 0]\n#     # your prediction code here\n#     current_test['answered_correctly'] = model.predict(current_test[features])  # 0.5\n#     set_predict(current_test.loc[:,['row_id', 'answered_correctly']])\n#     pbar.update(len(current_test))\n# print(f\"count {count} {len(predicted)}\")","metadata":{"papermill":{"duration":466.435487,"end_time":"2020-11-13T14:06:20.068150","exception":false,"start_time":"2020-11-13T13:58:33.632663","status":"completed"},"tags":[],"cellId":"hkq3ce6f9zot3ymxi9x1s","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nprior_test_df = None\nfor (test_df, sample_prediction_df) in iter_test:\n    if prior_test_df is not None:\n        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop = True)\n        \n        user_ids = prior_test_df['user_id'].values\n        content_ids = prior_test_df['content_id'].values\n        targets = prior_test_df[target].values\n\n        # for user_id, content_id, answered_correctly in prior_test_df[[\"user_id\", \"content_id\", target]].values:\n        for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n            user_sum_dict[user_id] += answered_correctly\n            user_count_dict[user_id] += 1\n            content_sum_dict[content_id] += answered_correctly\n            content_count_dict[content_id] += 1\n\n    prior_test_df = test_df.copy()\n    \n    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n    test_df.drop(labels=\"part\", axis=1, inplace=True)\n    test_df.content_id = test_df.content_id.astype(int)\n    \n    test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')    \n    user_sum = np.zeros(len(test_df), dtype = np.int32)\n    user_count = np.zeros(len(test_df), dtype = np.int32)\n    content_sum = np.zeros(len(test_df), dtype = np.int32)\n    content_count = np.zeros(len(test_df), dtype = np.int32)\n    \n    for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n        user_sum[i] = user_sum_dict[user_id]\n        user_count[i] = user_count_dict[user_id]\n        content_sum[i] = content_sum_dict[content_id]\n        content_count[i] = content_count_dict[content_id]\n\n    test_df['user_correctness'] = user_sum / user_count\n    test_df['content_count'] = content_count\n    test_df['content_id'] = content_sum / content_count\n    test_df[target] = model.predict_proba(test_df[features])[:,1]\n    set_predict(test_df[['row_id', target]])","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"yzork8xo17phg263eq5lvj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!M\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"r0wtm7br3uocd9325isg1s","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!M\n","metadata":{"cellId":"p86wo7s8oulxttelj13jdn","trusted":true},"outputs":[],"execution_count":null}]}