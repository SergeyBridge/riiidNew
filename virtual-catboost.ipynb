{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#!M\n",
    "# !pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n",
    "# %pip install --upgrade pip\n",
    "# %pip install -r /home/jupyter/work/resources/riiidNew/requirements.txt --upgrade\n",
    "# %pip install scipy  --ignore-installed scipy --upgrade\n",
    "# %pip install pyarrow==0.17.1\n",
    "# %pip install bayesian-optimization\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# if str(Path.home()) == \"/root\":  # DATASPHERE\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd()/'riiidNew'))\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pyarrow\n",
    "from collections import defaultdict\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from preprocess import preprocess_train_data\n",
    "from catboost_bayesian_search import bayesian_catboost_search, bayesian_catboost_searchCV, param_adjust_dtypes\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Error handling, ignore all\n",
    "np.seterr(divide = 'ignore', invalid = 'ignore')\n",
    "\n",
    "\n",
    "if str(Path.home()) == \"/home/sergey\":   # Home computer\n",
    "    kaggle_path = Path.cwd()/\"kaggle_tmp/\"\n",
    "    questions_df = pd.read_csv('/mnt/data30G/2020riiid/questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n",
    "    test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train_1e5.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid.feather\", columns=dtypes.keys())\n",
    "\n",
    "elif str(Path.home()) == \"/root\":   # DATASPHERE\n",
    "\n",
    "    path = Path.cwd()/\"riiidNew\"/\"data1\"\n",
    "    kaggle_path = Path.cwd()/\"riiidNew\"/\"kaggle\"\n",
    "    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n",
    "    train_df = pd.read_feather(path/\"train.feather\", columns=config.dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"train_5e6.feather\", columns=config.dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"train_1e5.feather\", columns=config.dtypes.keys())\n",
    "    # train_df = pd.read_pickle(path/'cv2_train.pickle.zip').astype(config.dtypes, errors=\"ignore\")\n",
    "    # test_df = pd.read_pickle(path/\"cv2_valid.pickle.zip\").astype(config.dtypes, errors=\"ignore\")\n",
    "\n",
    "elif str(Path.home()) == \"/home/riiid\":   # Virtual machine ycloud\n",
    "\n",
    "    path = Path.cwd()/\"data\"\n",
    "    kaggle_path = Path.cwd()/\"kaggle\"\n",
    "    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n",
    "    # train_df = pd.read_feather(path/\"train.feather\", columns=config.dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"train_5e6.feather\", columns=config.dtypes.keys())\n",
    "    # test_df = pd.read_feather(path/\"cv2_test_1e4.feather\", columns=config.dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"cv2_train_1e5.feather\", columns=config.dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"train_1e5.feather\", columns=config.dtypes.keys())\n",
    "#     train_df = train_df.iloc[:100]\n",
    "\n",
    "#print(f\"train_df shape = {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': 'AUC:hints=skip_train~false', 'task_type': 'GPU', 'grow_policy': 'Lossguide', 'iterations': 5000, 'learning_rate': 0.1, 'random_seed': 0, 'bootstrap_type': 'Bayesian', 'l2_leaf_reg': 0.5, 'depth': 10, 'max_leaves': 10, 'border_count': 128, 'verbose': 250, 'od_type': 'Iter', 'od_wait': 50}\n"
     ]
    }
   ],
   "source": [
    "print(config.prior_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess for CV ok\n",
      "optimizer_maxCV ..\n"
     ]
    }
   ],
   "source": [
    "# # Obtain new train_df and validation test_df\n",
    "# train_df = pd.read_feather(path/\"cv2_train.feather\", columns=config.dtypes.keys())\n",
    "# # train_df = pd.read_feather(path/\"train_1e5.feather\", columns=config.dtypes.keys())\n",
    "\n",
    "# # Preprocess for Bayesian CV\n",
    "# train_user_agg, train_content_agg, train_df = preprocess_train_data(train_df, questions_df, config.target, config.dtypes)\n",
    "# # test_user_agg, test_content_agg, test_df = preprocess_train_data(test_df, questions_df, config.target, config.dtypes)\n",
    "# print(\"Preprocess for CV ok\")\n",
    "\n",
    "\n",
    "# # Training and validating data\n",
    "# train_set = Pool(train_df[config.features], label = train_df[config.target], cat_features=config.cat_features)\n",
    "# val_set = Pool(test_df[config.features], label = test_df[config.target])\n",
    "\n",
    "# print(\"optimizer_maxCV ..\")\n",
    "# optimizer_maxCV = bayesian_catboost_searchCV(\n",
    "#     train_set,\n",
    "#     prior_params=config.prior_params,\n",
    "#     pds=config.pds, pds_dtypes=config.pds_dtypes,\n",
    "#     init_points=5, n_iter=7, verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess for model fitting ok\n",
      "|   iter    |  target   | baggin... | border... |   depth   | l2_lea... | max_le... |\n",
      "-------------------------------------------------------------------------------------\n",
      "0:\tlearn: 0.7716994\ttest: 0.7187736\tbest: 0.7187736 (0)\ttotal: 36.7ms\tremaining: 3m 3s\n",
      "bestTest = 0.7682361901\n",
      "bestIteration = 70\n",
      "Shrink model to first 71 iterations.\n",
      "0:\tlearn: 0.7705329\ttest: 0.7186846\tbest: 0.7186846 (0)\ttotal: 27.2ms\tremaining: 2m 15s\n",
      "bestTest = 0.7690668702\n",
      "bestIteration = 191\n",
      "Shrink model to first 192 iterations.\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7691  \u001b[0m | \u001b[95m 3.336   \u001b[0m | \u001b[95m 159.4   \u001b[0m | \u001b[95m 23.16   \u001b[0m | \u001b[95m 481.8   \u001b[0m | \u001b[95m 63.68   \u001b[0m |\n",
      "0:\tlearn: 0.7626809\ttest: 0.7196122\tbest: 0.7196122 (0)\ttotal: 17.2ms\tremaining: 1m 26s\n",
      "bestTest = 0.7708970308\n",
      "bestIteration = 184\n",
      "Shrink model to first 185 iterations.\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7709  \u001b[0m | \u001b[95m 4.021   \u001b[0m | \u001b[95m 182.2   \u001b[0m | \u001b[95m 17.66   \u001b[0m | \u001b[95m 462.8   \u001b[0m | \u001b[95m 19.95   \u001b[0m |\n",
      "0:\tlearn: 0.7434526\ttest: 0.6910856\tbest: 0.6910856 (0)\ttotal: 40.7ms\tremaining: 3m 23s\n",
      "bestTest = 0.7667251527\n",
      "bestIteration = 73\n",
      "Shrink model to first 74 iterations.\n",
      "0:\tlearn: 0.7675080\ttest: 0.7239474\tbest: 0.7239474 (0)\ttotal: 18.3ms\tremaining: 1m 31s\n",
      "bestTest = 0.7703488171\n",
      "bestIteration = 187\n",
      "Shrink model to first 188 iterations.\n",
      "0:\tlearn: 0.7748503\ttest: 0.7228481\tbest: 0.7228481 (0)\ttotal: 46.9ms\tremaining: 3m 54s\n",
      "bestTest = 0.7676643431\n",
      "bestIteration = 125\n",
      "Shrink model to first 126 iterations.\n",
      "0:\tlearn: 0.7762730\ttest: 0.7322874\tbest: 0.7322874 (0)\ttotal: 33.8ms\tremaining: 2m 48s\n",
      "bestTest = 0.7693817914\n",
      "bestIteration = 101\n",
      "Shrink model to first 102 iterations.\n",
      "0:\tlearn: 0.7486733\ttest: 0.7032410\tbest: 0.7032410 (0)\ttotal: 14.4ms\tremaining: 1m 12s\n",
      "250:\tlearn: 0.8217461\ttest: 0.7682093\tbest: 0.7694138 (213)\ttotal: 3.6s\tremaining: 1m 8s\n",
      "bestTest = 0.769413799\n",
      "bestIteration = 213\n",
      "Shrink model to first 214 iterations.\n",
      "0:\tlearn: 0.7764750\ttest: 0.7390696\tbest: 0.7390696 (0)\ttotal: 15.3ms\tremaining: 1m 16s\n",
      "bestTest = 0.7687746584\n",
      "bestIteration = 68\n",
      "Shrink model to first 69 iterations.\n",
      "0:\tlearn: 0.7577755\ttest: 0.7157297\tbest: 0.7157297 (0)\ttotal: 15.2ms\tremaining: 1m 15s\n",
      "250:\tlearn: 0.8149133\ttest: 0.7683118\tbest: 0.7688609 (208)\ttotal: 3.57s\tremaining: 1m 7s\n",
      "bestTest = 0.7688609362\n",
      "bestIteration = 208\n",
      "Shrink model to first 209 iterations.\n",
      "0:\tlearn: 0.7443748\ttest: 0.6946142\tbest: 0.6946142 (0)\ttotal: 16.1ms\tremaining: 1m 20s\n",
      "bestTest = 0.7698177695\n",
      "bestIteration = 88\n",
      "Shrink model to first 89 iterations.\n",
      "0:\tlearn: 0.7771067\ttest: 0.7358211\tbest: 0.7358211 (0)\ttotal: 15.7ms\tremaining: 1m 18s\n",
      "bestTest = 0.770216167\n",
      "bestIteration = 107\n",
      "Shrink model to first 108 iterations.\n",
      "=====================================================================================\n",
      "optimizer_max ..\n",
      "{'target': 0.7708970308303833, 'params': {'bagging_temperature': 4.021107678988524, 'border_count': 182.2237299382261, 'depth': 17.65675753859685, 'l2_leaf_reg': 462.813199818672, 'max_leaves': 19.94504814770417}}\n"
     ]
    }
   ],
   "source": [
    "# Obtain new train_df and validation test_df\n",
    "# train_df = pd.read_feather(path/\"cv2_train.feather\", columns=config.dtypes.keys())\n",
    "train_df = pd.read_feather(path/\"train_1e5.feather\", columns=config.dtypes.keys())\n",
    "\n",
    "\n",
    "# Preprocess for model fitting\n",
    "train_user_agg, train_content_agg, train_df = preprocess_train_data(train_df, questions_df, config.target, config.dtypes)\n",
    "print(\"Preprocess for model fitting ok\")\n",
    "\n",
    "# Ratio is 6/24 = 25%\n",
    "test_df = train_df.groupby('user_id').tail(6)\n",
    "train_df.drop(test_df.index, inplace = True)\n",
    "\n",
    "# Training and validating data\n",
    "train_set = Pool(train_df[config.features], label = train_df[config.target], cat_features=config.cat_features)\n",
    "val_set = Pool(test_df[config.features], label = test_df[config.target], cat_features=config.cat_features)\n",
    "\n",
    "\n",
    "optimizer_max = bayesian_catboost_search(\n",
    "    train_set, val_set,\n",
    "    prior_params=config.prior_params,\n",
    "    pds=config.pds, pds_dtypes=config.pds_dtypes,\n",
    "    init_points=5, n_iter=7, verbose=True,\n",
    ")\n",
    "\n",
    "print(\"optimizer_max ..\")\n",
    "print(optimizer_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess for model fitting ok\n",
      "params\n",
      "{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': 'AUC:hints=skip_train~false', 'task_type': 'GPU', 'grow_policy': 'Lossguide', 'iterations': 20000, 'learning_rate': 0.02, 'random_seed': 0, 'bootstrap_type': 'Bayesian', 'l2_leaf_reg': 462.813199818672, 'depth': 17, 'max_leaves': 19, 'border_count': 182, 'verbose': 250, 'od_type': 'Iter', 'od_wait': 50, 'bagging_temperature': 4.021107678988524}\n",
      "0:\tlearn: 0.7626809\ttest: 0.7196122\tbest: 0.7196122 (0)\ttotal: 19.2ms\tremaining: 6m 24s\n",
      "250:\tlearn: 0.8077318\ttest: 0.7669528\tbest: 0.7669566 (249)\ttotal: 4.19s\tremaining: 5m 29s\n",
      "500:\tlearn: 0.8144199\ttest: 0.7690084\tbest: 0.7690084 (500)\ttotal: 8.51s\tremaining: 5m 31s\n",
      "bestTest = 0.7690390646\n",
      "bestIteration = 506\n",
      "Shrink model to first 507 iterations.\n",
      "kaggle_path /home/riiid/riiidNew/kaggle\n",
      "model.get_best_score()\n",
      "{'learn': {'Logloss': 0.5184433600530507, 'AUC': 0.8157019317150116}, 'validation': {'Logloss': 0.56527326662497, 'AUC': 0.7690390646457672}}\n"
     ]
    }
   ],
   "source": [
    "# Obtain new train_df and validation test_df\n",
    "# train_df = pd.read_feather(path/\"cv2_train.feather\", columns=config.dtypes.keys())\n",
    "train_df = pd.read_feather(path/\"train_1e5.feather\", columns=config.dtypes.keys())\n",
    "\n",
    "\n",
    "# Preprocess for model fitting\n",
    "train_user_agg, train_content_agg, train_df = preprocess_train_data(train_df, questions_df, config.target, config.dtypes)\n",
    "print(\"Preprocess for model fitting ok\")\n",
    "\n",
    "# Ratio is 6/24 = 25%\n",
    "test_df = train_df.groupby('user_id').tail(6)\n",
    "train_df.drop(test_df.index, inplace = True)\n",
    "\n",
    "# Training and validating data\n",
    "train_set = Pool(train_df[config.features], label = train_df[config.target], cat_features=config.cat_features)\n",
    "val_set = Pool(test_df[config.features], label = test_df[config.target], cat_features=config.cat_features)\n",
    "\n",
    "\n",
    "# val_set = Pool(valid_df[features], label = valid_df[target])\n",
    "params = param_adjust_dtypes(config.prior_params,\n",
    "                             config.pds_dtypes,\n",
    "                             optimizer_max[\"params\"])\n",
    "params[\"learning_rate\"] = 2e-2\n",
    "params['iterations'] = 20000\n",
    "\n",
    "print(\"params\")\n",
    "print(params)\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Fitting\n",
    "model.fit(train_set, eval_set = val_set, use_best_model = True)\n",
    "print(f\"kaggle_path {kaggle_path}\")\n",
    "\n",
    "model.save_model(f\"{kaggle_path/'catboost.model'}\")\n",
    "\n",
    "print(\"model.get_best_score()\")\n",
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/riiid')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.home()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!M\n",
    "import pickle\n",
    "\n",
    "user_sum_dict = train_user_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "user_count_dict = train_user_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "content_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "content_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "for filename, dic in zip([\"user_sum_dict\", \"user_count_dict\", \"content_sum_dict\", \"content_count_dict\"],\n",
    "                         [user_sum_dict, user_count_dict, content_sum_dict, content_count_dict]):\n",
    "    with open(f'{kaggle_path}/{filename}.pickle', 'wb') as handle:\n",
    "        pickle.dump(dic, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validaten_flg = True\n",
    "if validaten_flg:\n",
    "    from emulator import Iter_Valid\n",
    "    iter_test = Iter_Valid(test_df,max_user=1000)\n",
    "    predicted = []\n",
    "    def set_predict(df):\n",
    "        predicted.append(df)\n",
    "else:\n",
    "    import riiideducation\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prior_test_df = None\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    if prior_test_df is not None:\n",
    "        prior_test_df[config.target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prior_test_df = prior_test_df[prior_test_df[config.target] != -1].reset_index(drop = True)\n",
    "\n",
    "        user_ids = prior_test_df['user_id'].values\n",
    "        content_ids = prior_test_df['content_id'].values\n",
    "        targets = prior_test_df[config.target].values\n",
    "\n",
    "        # for user_id, content_id, answered_correctly in prior_test_df[[\"user_id\", \"content_id\", target]].values:\n",
    "        for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n",
    "            user_sum_dict[user_id] += answered_correctly\n",
    "            user_count_dict[user_id] += 1\n",
    "            content_sum_dict[content_id] += answered_correctly\n",
    "            content_count_dict[content_id] += 1\n",
    "\n",
    "    prior_test_df = test_df.copy()\n",
    "\n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n",
    "    test_df.drop(labels=\"part\", axis=1, inplace=True)\n",
    "    test_df.content_id = test_df.content_id.astype(int)\n",
    "\n",
    "    test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')\n",
    "    user_sum = np.zeros(len(test_df), dtype = np.int32)\n",
    "    user_count = np.zeros(len(test_df), dtype = np.int32)\n",
    "    content_sum = np.zeros(len(test_df), dtype = np.int32)\n",
    "    content_count = np.zeros(len(test_df), dtype = np.int32)\n",
    "\n",
    "    for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n",
    "        user_sum[i] = user_sum_dict[user_id]\n",
    "        user_count[i] = user_count_dict[user_id]\n",
    "        content_sum[i] = content_sum_dict[content_id]\n",
    "        content_count[i] = content_count_dict[content_id]\n",
    "\n",
    "    test_df['user_correctness'] = user_sum / user_count\n",
    "    test_df['content_count'] = content_count\n",
    "    test_df['content_id'] = content_sum / content_count\n",
    "    test_df[config.target] = model.predict_proba(test_df[config.features])[:,1]\n",
    "    set_predict(test_df[['row_id', config.target]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
