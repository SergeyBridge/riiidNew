{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Yandex DataSphere Kernel",
   "language": "python"
  },
  "language_info": {
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "file_extension": ".py",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python"
  },
  "papermill": {
   "duration": 392.708184,
   "end_time": "2020-11-23T16:52:33.291774",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T16:46:00.583590",
   "version": "2.1.0"
  },
  "notebookId": "49f1538a-c226-4642-b21c-95b4d1717f3e"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "# !pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n",
    "# %pip install --upgrade pip\n",
    "# %pip install -r /home/jupyter/work/resources/riiidNew/requirements.txt --upgrade\n",
    "# print(\"ok\")"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 30.191831,
     "end_time": "2020-11-23T16:46:34.873724",
     "exception": false,
     "start_time": "2020-11-23T16:46:04.681893",
     "status": "completed"
    },
    "tags": [],
    "cellId": "r4gbiatk8h938d934p4aip",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from collections import defaultdict\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from catboost.utils import get_gpu_device_count\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# import riiideducation\n",
    "import torch\n",
    "import pickle\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# Error handling, ignore all\n",
    "np.seterr(divide = 'ignore', invalid = 'ignore')\n",
    "\n",
    "print(f\"pyarrow {pyarrow.__version__}\")\n",
    "print(f\"curdir {Path.cwd()}\")"
   ],
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 2.195965,
     "end_time": "2020-11-23T16:46:37.127434",
     "exception": false,
     "start_time": "2020-11-23T16:46:34.931469",
     "status": "completed"
    },
    "tags": [],
    "cellId": "t3n208wi88qtuu9cu40m",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow 2.0.0\n",
      "curdir /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/riiidNew\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "\n",
    "# Data config\n",
    "\n",
    "dtypes = {\n",
    "    'row_id': 'int64',\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32', \n",
    "    'content_id': 'int16', \n",
    "    'content_type_id': 'int8',\n",
    "    'task_container_id': 'int16',\n",
    "    'answered_correctly': 'int8', \n",
    "    'prior_question_elapsed_time': 'float32', \n",
    "    'prior_question_had_explanation': 'bool',\n",
    "    'user_answer': 'int8',\n",
    "}\n",
    "\n",
    "target = 'answered_correctly'\n",
    "\n",
    "homedir = Path.home()\n",
    "print(str(homedir))\n",
    "\n",
    "if str(homedir) == \"/home/sergey\":   # Home computer\n",
    "    kaggle_path = Path.cwd()/'kaggle_tmp'\n",
    "    questions_df = pd.read_csv('/mnt/data30G/2020riid/questions.csv', usecols = [0, 3],\n",
    "                               dtype = {'question_id': 'int16', 'part': 'int8'})\n",
    "    print(questions_df.head())\n",
    "    questions_df.set_index(keys=\"question_id\", inplace=True)\n",
    "    questions_df.index.names = [\"content_id\"]\n",
    "    print(questions_df.head())\n",
    "    # train_df = dt.fread('../input/riiid-test-answer-prediction/train.csv', columns = set(dtypes.keys())).to_pandas()\n",
    "    # train_df = dt.fread('/mnt/data30G/2020riid/train.csv', columns = set(dtypes.keys())).to_pandas()\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train_1e5.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid.feather\", columns=dtypes.keys())\n",
    "\n",
    "elif str(homedir) == \"/root\":   # Datasphere\n",
    "    \n",
    "    path = Path.cwd()/\"riiidNew\"/\"data\"\n",
    "    kaggle_path = Path.cwd()/\"riiidNew\"/\"kaggle\"\n",
    "    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n",
    "    questions_df.set_index(keys=\"question_id\", inplace=True)\n",
    "    questions_df.index.names = [\"content_id\"]\n",
    "#     train_df = pd.read_feather(path/\"cv1_train_1e5.feather\", columns=dtypes.keys())\n",
    "#     test_df = pd.read_feather(path/\"cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(path/\"data/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"cv1_train.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(path/\"cv1_valid.feather\", columns=dtypes.keys())\n",
    "    # train_df = dt.fread(path/'train.csv', columns=dtypes.keys()).to_pandas().astype(dtypes, errors=\"ignore\")\n",
    "    train_df = pd.read_pickle(path/\"cv1_train.pickle.zip\").astype(dtypes, errors=\"ignore\")\n",
    "    # train_df = train_df.iloc[:int(1e6)]\n",
    "    # test_df = pd.read_pickle(path/\"cv1_valid.pickle.zip\").astype(dtypes, errors=\"ignore\")\n",
    "    # test_df = test_df.iloc[:int(1e4)]\n",
    "\n",
    "print(f\"train_df shape = {train_df.shape}\")\n",
    "train_df.head()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019374,
     "end_time": "2020-11-23T16:46:37.206927",
     "exception": false,
     "start_time": "2020-11-23T16:46:37.187553",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "2w1su8za30ahv2yfmd5kho",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sergey\n",
      "   question_id  part\n",
      "0            0     1\n",
      "1            1     1\n",
      "2            2     1\n",
      "3            3     1\n",
      "4            4     1\n",
      "            part\n",
      "content_id      \n",
      "0              1\n",
      "1              1\n",
      "2              1\n",
      "3              1\n",
      "4              1\n",
      "train_df shape = (100000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     row_id  timestamp    user_id  content_id  content_type_id  \\\n0  32933156          0  705741139         128                0   \n1  32933157      20666  705741139        7860                0   \n2  32933158      39172  705741139        7922                0   \n3  32933159      58207  705741139         156                0   \n4  32933160      75779  705741139          51                0   \n\n   task_container_id  answered_correctly  prior_question_elapsed_time  \\\n0                  0                   1                          NaN   \n1                  1                   1                      16000.0   \n2                  2                   1                      19000.0   \n3                  3                   1                      17000.0   \n4                  4                   1                      17000.0   \n\n   prior_question_had_explanation  user_answer  \n0                            <NA>            0  \n1                           False            0  \n2                           False            1  \n3                           False            2  \n4                           False            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>answered_correctly</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>user_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32933156</td>\n      <td>0</td>\n      <td>705741139</td>\n      <td>128</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32933157</td>\n      <td>20666</td>\n      <td>705741139</td>\n      <td>7860</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16000.0</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32933158</td>\n      <td>39172</td>\n      <td>705741139</td>\n      <td>7922</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>19000.0</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32933159</td>\n      <td>58207</td>\n      <td>705741139</td>\n      <td>156</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>17000.0</td>\n      <td>False</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32933160</td>\n      <td>75779</td>\n      <td>705741139</td>\n      <td>51</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>17000.0</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Information of the training dataset"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.020594,
     "end_time": "2020-11-23T16:47:42.496580",
     "exception": false,
     "start_time": "2020-11-23T16:47:42.475986",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "cellId": "vk8q857fkbl0ou00kw2wqoe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "sep = '*' * 50\n",
    "print(f'Training dataset detailed information \\n{sep}')\n",
    "print(f'Columns: {train_df.columns} \\n{sep}')\n",
    "print(f'Shape: {train_df.shape} \\n{sep}')\n",
    "print(f'NA values in each column: {sum(train_df.isna().sum())} \\n{sep}')\n",
    "\n",
    "\n",
    "def prep_data(df, questions_df=questions_df, dtypes=dtypes):\n",
    "    # Exclude lectures\n",
    "    df = df[df[target] != -1].reset_index(drop=True, inplace=False)\n",
    "    # Fill NaN values in the 'prior_question_had_explanation' columns\n",
    "    df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "\n",
    "    # Set type\n",
    "    df = df.astype(dtypes)\n",
    "    \n",
    "    # Answer for the previous questions of users\n",
    "    df['lag'] = df.groupby('user_id')[target].shift()\n",
    "    # For each user (groupby('user_id')), compute the cummulative number of correct answers and number answers in general\n",
    "    groupby = df.groupby('user_id')['lag']\n",
    "    cum = groupby.agg(['cumsum', 'cumcount'])\n",
    "\n",
    "    # User correctness (measure the users' learning progress)\n",
    "    df['user_correctness'] = cum['cumsum'] / cum['cumcount']\n",
    "    # Drop the 'lag' feature\n",
    "    df.drop(columns=['lag'], inplace=True)\n",
    "    df.head()    \n",
    "    \n",
    "    # Overall correctness of users\n",
    "    user_agg = df.groupby('user_id')[target].agg(['sum', 'count'])\n",
    "    # Overall difficulty of questions\n",
    "    content_agg = df.groupby('content_id')[target].agg(['sum', 'count'])    \n",
    "\n",
    "    # Take only 24 last observations of each user\n",
    "    df = df.groupby('user_id').tail(24).reset_index(drop=True)\n",
    "    \n",
    "    df = df.join(questions_df, on='content_id' )\n",
    "    # df = pd.merge(df, questions_df, left_on='content_id', right_on='question_id', how='left')\n",
    "    # df.drop(columns=['question_id'], inplace=True)\n",
    "\n",
    "    # How many questions have been answered in each content ID?\n",
    "    df['content_count'] = df['content_id'].map(content_agg['count']).astype('int32')\n",
    "    # How hard are questions in each content ID?\n",
    "    df['content_difficalty'] = df['content_id'].map(content_agg['sum'] / content_agg['count'])\n",
    "    # df.drop('content_id', inplace=True, axis=1)\n",
    "\n",
    "    return user_agg, content_agg, df\n",
    "    "
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "2682tt4ygfdlfmc4zyeng",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset detailed information \n",
      "**************************************************\n",
      "Columns: Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation',\n",
      "       'user_answer'],\n",
      "      dtype='object') \n",
      "**************************************************\n",
      "Shape: (100000, 10) \n",
      "**************************************************\n",
      "NA values in each column: 5347 \n",
      "**************************************************\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract the validation set"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.021183,
     "end_time": "2020-11-23T16:48:53.873557",
     "exception": false,
     "start_time": "2020-11-23T16:48:53.852374",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "cellId": "hvfpq2wdqaf1hr8xwrqf4q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "train_user_agg, train_content_agg, train_df = prep_data(train_df)\n",
    "\n",
    "# user_sum_dict = train_user_agg['sum'].astype('int16').to_dict(defaultdict(int))\n",
    "# user_count_dict = train_user_agg['count'].astype('int16').to_dict(defaultdict(int))\n",
    "# content_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "# content_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "# gc.collect()\n",
    "\n",
    "\n",
    "# Ratio is 6/24 = 25%\n",
    "valid_df = train_df.groupby('user_id').tail(6)\n",
    "train_df.drop(valid_df.index, inplace = True)"
   ],
   "metadata": {
    "papermill": {
     "duration": 3.111291,
     "end_time": "2020-11-23T16:48:58.928890",
     "exception": false,
     "start_time": "2020-11-23T16:48:55.817599",
     "status": "completed"
    },
    "tags": [],
    "cellId": "s0e18onkl9mn8yt7bhussl",
    "trusted": true
   },
   "outputs": [],
   "execution_count": 138
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.023143,
     "end_time": "2020-11-23T16:48:58.975838",
     "exception": false,
     "start_time": "2020-11-23T16:48:58.952695",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "cellId": "suwfns3lzdchqhn90tmrsi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "# features = ['content_difficalty', \"content_id\", 'prior_question_elapsed_time',\n",
    "#             'prior_question_had_explanation', 'user_correctness',\n",
    "#             'part', 'content_count']\n",
    "\n",
    "features = ['content_difficalty', 'user_id', 'prior_question_elapsed_time',\n",
    "            'prior_question_had_explanation', 'user_correctness',\n",
    "            'part', 'content_count']\n",
    "\n",
    "params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'custom_metric': 'AUC:hints=skip_train~false',\n",
    "\n",
    "    'task_type': 'CPU',  # 'GPU' if get_gpu_device_count() > 0 else 'CPU',\n",
    "    # 'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n",
    "    'grow_policy': 'Lossguide',\n",
    "    'iterations': 2,\n",
    "    'learning_rate': 4e-3,\n",
    "    'random_seed': 0,\n",
    "    'l2_leaf_reg': 5e-1,\n",
    "    'depth': 10,\n",
    "    #'rsm': 0.3,\n",
    "    # 'max_leaves': 10,\n",
    "    'border_count': 128,\n",
    "    'verbose': 150,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 50,\n",
    "}\n",
    "print(params)\n",
    "\n",
    "# Training and validating data\n",
    "train_set = Pool(train_df[features], label = train_df[target])\n",
    "val_set = Pool(valid_df[features], label = valid_df[target])\n",
    "# val_set = Pool(test_df[features], label = test_df[target])\n",
    "\n",
    "# Model definition\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Fitting\n",
    "model.fit(train_set, eval_set = val_set, use_best_model = True)\n",
    "print(f\"kaggle_path {kaggle_path}\")\n",
    "\n",
    "model.save_model(str(kaggle_path/'catboost.model'))"
   ],
   "metadata": {
    "papermill": {
     "duration": 207.603145,
     "end_time": "2020-11-23T16:52:31.347675",
     "exception": false,
     "start_time": "2020-11-23T16:49:03.744530",
     "status": "completed"
    },
    "tags": [],
    "cellId": "o8jdczcyj1h3jkjzlxzy9w",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': 'AUC:hints=skip_train~false', 'task_type': 'CPU', 'grow_policy': 'Lossguide', 'iterations': 2, 'learning_rate': 0.004, 'random_seed': 0, 'l2_leaf_reg': 0.5, 'depth': 10, 'border_count': 128, 'verbose': 150, 'od_type': 'Iter', 'od_wait': 50}\n",
      "0:\tlearn: 0.7758269\ttest: 0.7631521\tbest: 0.7631521 (0)\ttotal: 35.7ms\tremaining: 35.7ms\n",
      "1:\tlearn: 0.7812295\ttest: 0.7702233\tbest: 0.7702233 (1)\ttotal: 63.3ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7702233275\n",
      "bestIteration = 1\n",
      "\n",
      "kaggle_path /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/riiidNew/kaggle_tmp\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'task_type': 'GPU', 'grow_policy': 'Lossguide', 'iterations': 15000, 'learning_rate': 0.01, 'random_seed': 0, 'l2_leaf_reg': 0.1, 'depth': 8, 'border_count': 128, 'verbose': 150, 'od_type': 'Iter', 'od_wait': 50}\n",
    "bestTest = 0.7371392846\n",
    "\n",
    "bestTest = 0.7370638549\n",
    "bestTest = 0.7364509702\n"
   ],
   "metadata": {
    "cellId": "nl7v0tm6byjfdfngg11ydh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.get_best_score()"
   ],
   "metadata": {
    "cellId": "c1pc7wh24o8ipu8gk23jbh",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'learn': {'Logloss': 0.6912894493875078, 'AUC': 0.7812294949729874},\n 'validation': {'Logloss': 0.6914273813025933, 'AUC': 0.7702233274556736}}"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "95"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "del train_df\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.051177,
     "end_time": "2020-11-23T16:52:31.451640",
     "exception": false,
     "start_time": "2020-11-23T16:52:31.400463",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "cellId": "ba4wdwyypnjxlgzfd769b9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "mean_dict = {\n",
    "    'user_sum_dict': train_user_agg['sum'].astype('int16').to_dict(defaultdict(int)),\n",
    "    'user_count_dict': train_user_agg['count'].astype('int16').to_dict(defaultdict(int)),\n",
    "    'content_sum_dict': train_content_agg['sum'].astype('int32').to_dict(defaultdict(int)),\n",
    "    'content_count_dict': train_content_agg['count'].astype('int32').to_dict(defaultdict(int)),\n",
    "\n",
    "}\n",
    "\n",
    "# for filename, dic in mean_dict.items():\n",
    "#     with open(f'{kaggle_path}/{filename}.pickle', 'wb') as handle:\n",
    "#         pickle.dump(dic, handle)\n",
    "\n",
    "# with open(f\"{kaggle_path/'mean_dict.pickle'}\", 'wb') as handle:\n",
    "#     pickle.dump(mean_dict, handle)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.618845,
     "end_time": "2020-11-23T16:52:32.122494",
     "exception": false,
     "start_time": "2020-11-23T16:52:31.503649",
     "status": "completed"
    },
    "tags": [],
    "cellId": "7ui7ur3vc7044m7d88w7h2",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_df\n"
     ]
    },
    {
     "data": {
      "text/plain": "         sum_  count_\nuser_id              \n44331       4       7\n1084314    21      33\n1250518    15      50\n1744476     3       7\n2393889    22      30",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sum_</th>\n      <th>count_</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44331</th>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1084314</th>\n      <td>21</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>1250518</th>\n      <td>15</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1744476</th>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2393889</th>\n      <td>22</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = pd.DataFrame(data={\n",
    "    'sum_': train_user_agg['sum'].astype('int32'),\n",
    "    'count_': train_user_agg['count'].astype('int32')\n",
    "})\n",
    "print(\"user_df\")\n",
    "user_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_df\n"
     ]
    },
    {
     "data": {
      "text/plain": "            sum_  count_\ncontent_id              \n0              9      10\n1              9       9\n2             33      70\n3             23      32\n4             66     117",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sum_</th>\n      <th>count_</th>\n    </tr>\n    <tr>\n      <th>content_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66</td>\n      <td>117</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df = pd.DataFrame(data={\n",
    "    'sum_': train_content_agg['sum'].astype('int32'),\n",
    "    'count_': train_content_agg['count'].astype('int32')\n",
    "})\n",
    "print(\"content_df\")\n",
    "content_df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation',\n",
      "       'user_answer', 'user_correctness', 'part', 'content_count',\n",
      "       'content_difficalty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "\n",
    "test_user_agg, test_content_agg, test_df = prep_data(test_df)\n",
    "print(test_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "     row_id    timestamp     user_id  content_id  content_type_id  \\\n0     45253   2146476402     1186307        4451                0   \n1  91995999   4916060626  1951897185        8534                0   \n2  99237056        33806  2105538840        5631                0   \n3  55360606    701477552  1174413790        5168                0   \n4  44070864  11040265647   932625141         412                0   \n\n   task_container_id  answered_correctly  prior_question_elapsed_time  \\\n0                370                   1                      10000.0   \n1                504                   0                      47000.0   \n2                  1                   1                      21000.0   \n3                221                   0                      69000.0   \n4                390                   1                      16000.0   \n\n   prior_question_had_explanation  user_answer  part  \n0                            True            3     5  \n1                            True            3     5  \n2                           False            2     5  \n3                            True            0     5  \n4                            True            3     2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>answered_correctly</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>user_answer</th>\n      <th>part</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45253</td>\n      <td>2146476402</td>\n      <td>1186307</td>\n      <td>4451</td>\n      <td>0</td>\n      <td>370</td>\n      <td>1</td>\n      <td>10000.0</td>\n      <td>True</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91995999</td>\n      <td>4916060626</td>\n      <td>1951897185</td>\n      <td>8534</td>\n      <td>0</td>\n      <td>504</td>\n      <td>0</td>\n      <td>47000.0</td>\n      <td>True</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99237056</td>\n      <td>33806</td>\n      <td>2105538840</td>\n      <td>5631</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>21000.0</td>\n      <td>False</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55360606</td>\n      <td>701477552</td>\n      <td>1174413790</td>\n      <td>5168</td>\n      <td>0</td>\n      <td>221</td>\n      <td>0</td>\n      <td>69000.0</td>\n      <td>True</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44070864</td>\n      <td>11040265647</td>\n      <td>932625141</td>\n      <td>412</td>\n      <td>0</td>\n      <td>390</td>\n      <td>1</td>\n      <td>16000.0</td>\n      <td>True</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(labels=['user_correctness', 'content_count', 'content_difficalty'], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 ms, sys: 0 ns, total: 26.3 ms\n",
      "Wall time: 26.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validaten_flg = True\n",
    "if validaten_flg:\n",
    "    from emulator import Iter_Valid\n",
    "    iter_test = Iter_Valid(test_df,max_user=1000)\n",
    "    predicted = []\n",
    "    def set_predict(df):\n",
    "        predicted.append(df)\n",
    "else:\n",
    "    import riiideducation\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "# cumcount = sum([len(df) for df in predicted])\n",
    "# count = 0\n",
    "# pbar = tqdm(total=cumcount)\n",
    "# previous_test_df = None\n",
    "# for (current_test, current_prediction_df) in iter_test:\n",
    "#     count+=1\n",
    "#     if previous_test_df is not None:\n",
    "#         answers = eval(current_test[\"prior_group_answers_correct\"].iloc[0])\n",
    "#         responses = eval(current_test[\"prior_group_responses\"].iloc[0])\n",
    "#         previous_test_df['answered_correctly'] = answers\n",
    "#         previous_test_df['user_answer'] = responses\n",
    "#         # your feature extraction and model training code here\n",
    "#     previous_test_df = current_test.copy()\n",
    "#     current_test = current_test[current_test.content_type_id == 0]\n",
    "#     # your prediction code here\n",
    "#     current_test['answered_correctly'] = model.predict(current_test[features])  # 0.5\n",
    "#     set_predict(current_test.loc[:,['row_id', 'answered_correctly']])\n",
    "#     pbar.update(len(current_test))\n",
    "# print(f\"count {count} {len(predicted)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count loop starting 0\n",
      "count loop finished 0\n",
      "count loop starting 1\n",
      "count loop finished 1\n",
      "count loop starting 2\n",
      "True\n",
      "True\n",
      "count loop finished 2\n",
      "count loop starting 3\n",
      "True\n",
      "True\n",
      "count loop finished 3\n",
      "count loop starting 4\n",
      "True\n",
      "True\n",
      "count loop finished 4\n",
      "count loop starting 5\n",
      "True\n",
      "True\n",
      "count loop finished 5\n",
      "count loop starting 6\n",
      "True\n",
      "True\n",
      "count loop finished 6\n",
      "count loop starting 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:20: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<timed exec>:20: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<timed exec>:20: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<timed exec>:20: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<timed exec>:20: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<timed exec>:20: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Join on level between two MultiIndex objects is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001B[0m in \u001B[0;36mflex_wrapper\u001B[0;34m(self, other, level, fill_value, axis)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 413\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_binop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfill_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfill_value\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    414\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    415\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m_binop\u001B[0;34m(self, other, func, level, fill_value)\u001B[0m\n\u001B[1;32m   2715\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2716\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mequals\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2717\u001B[0;31m             \u001B[0mthis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mother\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malign\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjoin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"outer\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2718\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2719\u001B[0m         \u001B[0mthis_vals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mother_vals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfill_binop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfill_value\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36malign\u001B[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001B[0m\n\u001B[1;32m   4272\u001B[0m         \u001B[0mbroadcast_axis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4273\u001B[0m     ):\n\u001B[0;32m-> 4274\u001B[0;31m         return super().align(\n\u001B[0m\u001B[1;32m   4275\u001B[0m             \u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4276\u001B[0m             \u001B[0mjoin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36malign\u001B[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001B[0m\n\u001B[1;32m   8557\u001B[0m             )\n\u001B[1;32m   8558\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 8559\u001B[0;31m             return self._align_series(\n\u001B[0m\u001B[1;32m   8560\u001B[0m                 \u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8561\u001B[0m                 \u001B[0mjoin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m_align_series\u001B[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001B[0m\n\u001B[1;32m   8660\u001B[0m                 \u001B[0mjoin_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlidx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mridx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8661\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 8662\u001B[0;31m                 join_index, lidx, ridx = self.index.join(\n\u001B[0m\u001B[1;32m   8663\u001B[0m                     \u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_indexers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8664\u001B[0m                 )\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mjoin\u001B[0;34m(self, other, how, level, return_indexers, sort)\u001B[0m\n\u001B[1;32m   3448\u001B[0m         \u001B[0;31m# join on the level\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3449\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlevel\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself_is_mi\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mother_is_mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3450\u001B[0;31m             return self._join_level(\n\u001B[0m\u001B[1;32m   3451\u001B[0m                 \u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_indexers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_indexers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3452\u001B[0m             )\n",
      "\u001B[0;32m~/anaconda3/envs/riiidNew/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_join_level\u001B[0;34m(self, other, level, how, return_indexers, keep_order)\u001B[0m\n\u001B[1;32m   3678\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3679\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMultiIndex\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMultiIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3680\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Join on level between two MultiIndex objects is ambiguous\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3682\u001B[0m         \u001B[0mleft\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mright\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Join on level between two MultiIndex objects is ambiguous"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prior_test_df = None\n",
    "count = 0\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    print(\"count loop starting\", count)\n",
    "\n",
    "    if prior_test_df is not None:\n",
    "\n",
    "        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "\n",
    "        prior_user_id_idx = prior_test_df.index.get_level_values(\"user_id\")\n",
    "        content_id_idx = prior_test_df.index.get_level_values(\"content_id\")\n",
    "\n",
    "        new_users = prior_test_df.loc[~prior_user_id_idx.isin(user_df.index)]\n",
    "        new_user_id_idx = new_users.index.get_level_values(\"user_id\").drop_duplicates()\n",
    "\n",
    "        if len(new_users) > 0:\n",
    "            new_users_df = pd.DataFrame(data=0, index=new_user_id_idx, columns=user_df.columns, )\n",
    "            user_df = user_df.append(new_users_df, sort=True)\n",
    "\n",
    "        user_df.sum_ = \\\n",
    "            user_df.sum_.add(prior_test_df[target], fill_value=0, level=\"user_id\")\n",
    "        #\n",
    "        # user_df.count_ = \\\n",
    "        #     user_df.count_.add(1, fill_value=0, level=\"user_id\")\n",
    "        #\n",
    "        # content_df.sum_ = \\\n",
    "        #     content_df.sum_.add(prior_test_df[target], fill_value=0, level=\"content_id\")\n",
    "        #\n",
    "        # content_df.count_ = \\\n",
    "        #     user_df.count_.add(1, fill_value=0, level=\"content_id\")\n",
    "\n",
    "\n",
    "    test_df = test_df[test_df['content_type_id'] == 0]  # .reset_index(drop=True)\n",
    "    test_df.set_index([\"user_id\", \"content_id\"], inplace=True)\n",
    "    prior_test_df = test_df.copy()\n",
    "\n",
    "    test_df.drop(labels=\"part\", axis=1, inplace=True)\n",
    "\n",
    "    if count > 1:\n",
    "        print(test_df.index.is_unique)\n",
    "    test_df = test_df.join(questions_df, how='left')\n",
    "\n",
    "    user_correctness = pd.Series(data=(user_df.sum_ / user_df.count_).values, name=\"user_correctness\")\n",
    "    user_correctness.index.names = [\"user_id\"]\n",
    "\n",
    "    content_difficalty = pd.Series(data=(content_df.sum_ / content_df.count_).values, name=\"content_difficalty\")\n",
    "    content_difficalty.index.names = [\"content_id\"]\n",
    "\n",
    "    content_count = pd.Series(data=content_df.count_.values, name=\"content_count\")\n",
    "    content_count.index.names = [\"content_id\"]\n",
    "\n",
    "    test_df = test_df.join(content_count)\n",
    "    test_df = test_df.join(content_difficalty)\n",
    "    test_df = test_df.join(user_correctness)\n",
    "\n",
    "    test_df.reset_index(inplace=True)\n",
    "\n",
    "    test_df[target] = model.predict_proba(test_df[features])[:,1]\n",
    "    set_predict(test_df[['row_id', target]])\n",
    "\n",
    "    print(\"count loop finished\", count)\n",
    "    count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# %%time\n",
    "#\n",
    "# prior_test_df = None\n",
    "# count = 0\n",
    "# for (test_df, sample_prediction_df) in iter_test:\n",
    "#     if prior_test_df is not None:\n",
    "#         prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "#         prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop = True)\n",
    "#\n",
    "#         # user_ids = prior_test_df['user_id'].values\n",
    "#         # content_ids = prior_test_df['content_id'].values\n",
    "#         # targets = prior_test_df[target].values\n",
    "#\n",
    "#         for idx, (user_id, content_id, target) in prior_test_df[[\"user_id\", \"content_id\", target]].iterrows():\n",
    "#         # for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n",
    "#             mean_dict['user_sum_dict'][user_id] += target\n",
    "#             mean_dict['user_count_dict'][user_id] += 1\n",
    "#             mean_dict['content_sum_dict'][content_id] += target\n",
    "#             mean_dict['content_count_dict'][content_id] += 1\n",
    "#\n",
    "#     if count < 1:\n",
    "#         print(type(mean_dict['user_sum_dict']))\n",
    "#         # mean_df = pd.DataFrame.from_dict(mean_dict['user_sum_dict'])\n",
    "#         count = 1\n",
    "#         # print(mean_df)\n",
    "#\n",
    "#     prior_test_df = test_df.copy()\n",
    "#\n",
    "#     test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n",
    "#     test_df.drop(labels=\"part\", axis=1, inplace=True)\n",
    "#     test_df.content_id = test_df.content_id.astype(int)\n",
    "#\n",
    "#     test_df = pd.merge(test_df, questions_df, left_on = 'content_id',\n",
    "#                        right_on = 'question_id', how = 'left', right_index=True)\n",
    "#     test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')\n",
    "#\n",
    "#     user_sum = np.zeros(len(test_df), dtype = np.int16)\n",
    "#     user_count = np.zeros(len(test_df), dtype = np.int16)\n",
    "#     content_sum = np.zeros(len(test_df), dtype = np.int32)\n",
    "#     content_count = np.zeros(len(test_df), dtype = np.int32)\n",
    "#\n",
    "#     # \"for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n",
    "#     for i, (user_id, content_id) in test_df[['user_id', 'content_id']].iterrows():\n",
    "#         user_sum[i] = mean_dict['user_sum_dict'][user_id]\n",
    "#         user_count[i] = mean_dict['user_count_dict'][user_id]\n",
    "#         content_sum[i] = mean_dict['content_sum_dict'][content_id]\n",
    "#         content_count[i] = mean_dict['content_count_dict'][content_id]\n",
    "#\n",
    "#     test_df['user_correctness'] = user_sum / user_count\n",
    "#     test_df['content_count'] = content_count\n",
    "#     test_df['content_id'] = content_sum / content_count\n",
    "#\n",
    "#     test_df[target] = model.predict_proba(test_df[features])[:,1]\n",
    "#     set_predict(test_df[['row_id', target]])\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(predicted) 7\n",
      "     row_id  answered_correctly\n",
      "0     45253            0.498758\n",
      "1  91995999            0.497171\n",
      "2  99237056            0.497832\n",
      "3  55360606            0.502441\n",
      "4  44070864            0.498758\n"
     ]
    }
   ],
   "source": [
    "print(\"len(predicted)\", len(predicted))\n",
    "\n",
    "print(predicted[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 13)"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}