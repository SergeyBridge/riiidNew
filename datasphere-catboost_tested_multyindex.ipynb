{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python"},"papermill":{"duration":392.708184,"end_time":"2020-11-23T16:52:33.291774","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-11-23T16:46:00.583590","version":"2.1.0"},"notebookId":"763d612c-3280-43b0-b4f6-5be5450394c6"},"cells":[{"cell_type":"code","source":"#!M\n# !pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n%pip install --upgrade pip\n%pip install -r /home/jupyter/work/resources/riiidNew/requirements.txt --upgrade\nprint(\"ok\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":30.191831,"end_time":"2020-11-23T16:46:34.873724","exception":false,"start_time":"2020-11-23T16:46:04.681893","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"r4gbiatk8h938d934p4aip","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting pip\n  Downloading pip-20.3.3-py2.py3-none-any.whl (1.5 MB)\n\u001B[K     |████████████████████████████████| 1.5 MB 3.6 MB/s \n\u001B[?25hInstalling collected packages: pip\nSuccessfully installed pip-20.3.3\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting Pillow==6.2.2\n  Downloading Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n\u001B[K     |████████████████████████████████| 2.1 MB 3.0 MB/s \n\u001B[?25hCollecting torch==1.6.0\n  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n\u001B[K     |████████████████████████████████| 748.8 MB 5.6 kB/s \n\u001B[?25hCollecting tqdm==4.53\n  Downloading tqdm-4.53.0-py2.py3-none-any.whl (70 kB)\n\u001B[K     |████████████████████████████████| 70 kB 11.2 MB/s \n\u001B[?25hCollecting catboost\n  Downloading catboost-0.24.3-cp37-none-manylinux1_x86_64.whl (66.1 MB)\n\u001B[K     |████████████████████████████████| 66.1 MB 64 kB/s \n\u001B[?25hCollecting numpy\n  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n\u001B[K     |████████████████████████████████| 14.5 MB 70.7 MB/s \n\u001B[?25hCollecting pandas\n  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n\u001B[K     |████████████████████████████████| 9.5 MB 4.7 MB/s \n\u001B[?25hCollecting python-dateutil>=2.7.3\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n\u001B[K     |████████████████████████████████| 227 kB 82.2 MB/s \n\u001B[?25hCollecting pytz>=2017.2\n  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n\u001B[K     |████████████████████████████████| 509 kB 91.9 MB/s \n\u001B[?25hCollecting six\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting dask\n  Downloading dask-2020.12.0-py3-none-any.whl (884 kB)\n\u001B[K     |████████████████████████████████| 884 kB 91.0 MB/s \n\u001B[?25hCollecting datatable\n  Downloading datatable-0.11.1-cp37-cp37m-manylinux2010_x86_64.whl (83.9 MB)\n\u001B[K     |████████████████████████████████| 83.9 MB 69 kB/s \n\u001B[?25hCollecting lightgbm\n  Downloading lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\n\u001B[K     |████████████████████████████████| 1.8 MB 69.9 MB/s \n\u001B[?25hCollecting scikit-learn!=0.22.0\n  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n\u001B[K     |████████████████████████████████| 6.8 MB 4.6 kB/s \n\u001B[?25hCollecting joblib>=0.11\n  Downloading joblib-1.0.0-py3-none-any.whl (302 kB)\n\u001B[K     |████████████████████████████████| 302 kB 98.3 MB/s \n\u001B[?25hCollecting scipy\n  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n\u001B[K     |████████████████████████████████| 25.9 MB 3.4 MB/s \n\u001B[?25hCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\nCollecting matplotlib\n  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n\u001B[K     |████████████████████████████████| 11.6 MB 82.0 MB/s \n\u001B[?25hCollecting cycler>=0.10\n  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nCollecting kiwisolver>=1.0.1\n  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n\u001B[K     |████████████████████████████████| 1.1 MB 83.1 MB/s \n\u001B[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n\u001B[K     |████████████████████████████████| 67 kB 6.5 MB/s \n\u001B[?25hCollecting plotly\n  Downloading plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\n\u001B[K     |████████████████████████████████| 13.2 MB 711 kB/s \n\u001B[?25hCollecting retrying>=1.3.3\n  Downloading retrying-1.3.3.tar.gz (10 kB)\nCollecting seaborn\n  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\n\u001B[K     |████████████████████████████████| 283 kB 70.1 MB/s \n\u001B[?25hCollecting wget\n  Downloading wget-3.2.zip (10 kB)\nCollecting wheel\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\n\u001B[K     |████████████████████████████████| 829 kB 73.0 MB/s \n\u001B[?25hCollecting graphviz\n  Downloading graphviz-0.15-py2.py3-none-any.whl (18 kB)\nCollecting pyyaml\n  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n\u001B[K     |████████████████████████████████| 269 kB 95.7 MB/s \n\u001B[?25hBuilding wheels for collected packages: retrying, wget, future, pyyaml\n  Building wheel for retrying (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=9530 sha256=9fdc70313da16dc12d3372e566b0b2a2767071e7ad27eba816ee7a9453daa3f9\n  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n  Building wheel for wget (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=11569 sha256=2bc1b3881af802e8e440045c86d3b071fe5c32cfa75e2f9bd2fb59965b1c80b7\n  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n  Building wheel for future (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=493275 sha256=c05002758783879ea02093f213a6766005a626c9ddb830a83ed34003d7985178\n  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n  Building wheel for pyyaml (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=45920 sha256=7c4445b2c8c22200e878251d653e9cfca11f764e9746234bbe379899773f5cd9\n  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\nSuccessfully built retrying wget future pyyaml\nInstalling collected packages: six, numpy, threadpoolctl, scipy, retrying, pytz, python-dateutil, pyparsing, Pillow, kiwisolver, joblib, cycler, wheel, scikit-learn, pyyaml, plotly, pandas, matplotlib, graphviz, future, wget, tqdm, torch, seaborn, lightgbm, datatable, dask, catboost\nSuccessfully installed Pillow-6.2.2 catboost-0.24.3 cycler-0.10.0 dask-2020.12.0 datatable-0.11.1 future-0.18.2 graphviz-0.15 joblib-1.0.0 kiwisolver-1.3.1 lightgbm-3.1.1 matplotlib-3.3.3 numpy-1.19.4 pandas-1.1.5 plotly-4.14.1 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 retrying-1.3.3 scikit-learn-0.23.2 scipy-1.5.4 seaborn-0.11.0 six-1.15.0 threadpoolctl-2.1.0 torch-1.6.0 tqdm-4.53.0 wget-3.2 wheel-0.36.2\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting pip\n  Using cached pip-20.3.3-py2.py3-none-any.whl (1.5 MB)\nInstalling collected packages: pip\nSuccessfully installed pip-20.3.3\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting Pillow==6.2.2\n  Using cached Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\nCollecting torch==1.6.0\n  Using cached torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\nCollecting tqdm==4.53\n  Using cached tqdm-4.53.0-py2.py3-none-any.whl (70 kB)\nCollecting catboost\n  Using cached catboost-0.24.3-cp37-none-manylinux1_x86_64.whl (66.1 MB)\nCollecting numpy\n  Using cached numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\nCollecting pandas\n  Using cached pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\nCollecting python-dateutil>=2.7.3\n  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting pytz>=2017.2\n  Using cached pytz-2020.4-py2.py3-none-any.whl (509 kB)\nCollecting six\n  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting dask\n  Using cached dask-2020.12.0-py3-none-any.whl (884 kB)\nCollecting datatable\n  Using cached datatable-0.11.1-cp37-cp37m-manylinux2010_x86_64.whl (83.9 MB)\nCollecting lightgbm\n  Using cached lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\nCollecting scikit-learn!=0.22.0\n  Using cached scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\nCollecting joblib>=0.11\n  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\nCollecting scipy\n  Using cached scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\nCollecting threadpoolctl>=2.0.0\n  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\nCollecting matplotlib\n  Using cached matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\nCollecting cycler>=0.10\n  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nCollecting kiwisolver>=1.0.1\n  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\nCollecting plotly\n  Using cached plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\nCollecting retrying>=1.3.3\n  Using cached retrying-1.3.3-py3-none-any.whl\nCollecting pyarrow\n  Downloading pyarrow-0.17.1-cp37-cp37m-manylinux2014_x86_64.whl (63.8 MB)\n\u001B[K     |████████████████████████████████| 63.8 MB 71 kB/s s eta 0:00:01\n\u001B[?25hCollecting seaborn\n  Using cached seaborn-0.11.0-py3-none-any.whl (283 kB)\nCollecting wget\n  Using cached wget-3.2-py3-none-any.whl\nCollecting wheel\n  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting future\n  Using cached future-0.18.2-py3-none-any.whl\nCollecting graphviz\n  Using cached graphviz-0.15-py2.py3-none-any.whl (18 kB)\nCollecting pyyaml\n  Using cached PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: six, numpy, threadpoolctl, scipy, retrying, pytz, python-dateutil, pyparsing, Pillow, kiwisolver, joblib, cycler, wheel, scikit-learn, pyyaml, plotly, pandas, matplotlib, graphviz, future, wget, tqdm, torch, seaborn, pyarrow, lightgbm, datatable, dask, catboost\nSuccessfully installed Pillow-6.2.2 catboost-0.24.3 cycler-0.10.0 dask-2020.12.0 datatable-0.11.1 future-0.18.2 graphviz-0.15 joblib-1.0.0 kiwisolver-1.3.1 lightgbm-3.1.1 matplotlib-3.3.3 numpy-1.19.4 pandas-1.1.5 plotly-4.14.1 pyarrow-0.17.1 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 retrying-1.3.3 scikit-learn-0.23.2 scipy-1.5.4 seaborn-0.11.0 six-1.15.0 threadpoolctl-2.1.0 torch-1.6.0 tqdm-4.53.0 wget-3.2 wheel-0.36.2\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting pip\n  Downloading pip-20.3.3-py2.py3-none-any.whl (1.5 MB)\n\u001B[K     |████████████████████████████████| 1.5 MB 3.6 MB/s \n\u001B[?25hInstalling collected packages: pip\nSuccessfully installed pip-20.3.3\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting Pillow==6.2.2\n  Downloading Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n\u001B[K     |████████████████████████████████| 2.1 MB 3.0 MB/s \n\u001B[?25hCollecting torch==1.6.0\n  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n\u001B[K     |████████████████████████████████| 748.8 MB 5.6 kB/s \n\u001B[?25hCollecting tqdm==4.53\n  Downloading tqdm-4.53.0-py2.py3-none-any.whl (70 kB)\n\u001B[K     |████████████████████████████████| 70 kB 11.2 MB/s \n\u001B[?25hCollecting catboost\n  Downloading catboost-0.24.3-cp37-none-manylinux1_x86_64.whl (66.1 MB)\n\u001B[K     |████████████████████████████████| 66.1 MB 64 kB/s \n\u001B[?25hCollecting numpy\n  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n\u001B[K     |████████████████████████████████| 14.5 MB 70.7 MB/s \n\u001B[?25hCollecting pandas\n  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n\u001B[K     |████████████████████████████████| 9.5 MB 4.7 MB/s \n\u001B[?25hCollecting python-dateutil>=2.7.3\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n\u001B[K     |████████████████████████████████| 227 kB 82.2 MB/s \n\u001B[?25hCollecting pytz>=2017.2\n  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n\u001B[K     |████████████████████████████████| 509 kB 91.9 MB/s \n\u001B[?25hCollecting six\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting dask\n  Downloading dask-2020.12.0-py3-none-any.whl (884 kB)\n\u001B[K     |████████████████████████████████| 884 kB 91.0 MB/s \n\u001B[?25hCollecting datatable\n  Downloading datatable-0.11.1-cp37-cp37m-manylinux2010_x86_64.whl (83.9 MB)\n\u001B[K     |████████████████████████████████| 83.9 MB 69 kB/s \n\u001B[?25hCollecting lightgbm\n  Downloading lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\n\u001B[K     |████████████████████████████████| 1.8 MB 69.9 MB/s \n\u001B[?25hCollecting scikit-learn!=0.22.0\n  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n\u001B[K     |████████████████████████████████| 6.8 MB 4.6 kB/s \n\u001B[?25hCollecting joblib>=0.11\n  Downloading joblib-1.0.0-py3-none-any.whl (302 kB)\n\u001B[K     |████████████████████████████████| 302 kB 98.3 MB/s \n\u001B[?25hCollecting scipy\n  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n\u001B[K     |████████████████████████████████| 25.9 MB 3.4 MB/s \n\u001B[?25hCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\nCollecting matplotlib\n  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n\u001B[K     |████████████████████████████████| 11.6 MB 82.0 MB/s \n\u001B[?25hCollecting cycler>=0.10\n  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nCollecting kiwisolver>=1.0.1\n  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n\u001B[K     |████████████████████████████████| 1.1 MB 83.1 MB/s \n\u001B[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n\u001B[K     |████████████████████████████████| 67 kB 6.5 MB/s \n\u001B[?25hCollecting plotly\n  Downloading plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\n\u001B[K     |████████████████████████████████| 13.2 MB 711 kB/s \n\u001B[?25hCollecting retrying>=1.3.3\n  Downloading retrying-1.3.3.tar.gz (10 kB)\nCollecting seaborn\n  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\n\u001B[K     |████████████████████████████████| 283 kB 70.1 MB/s \n\u001B[?25hCollecting wget\n  Downloading wget-3.2.zip (10 kB)\nCollecting wheel\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\n\u001B[K     |████████████████████████████████| 829 kB 73.0 MB/s \n\u001B[?25hCollecting graphviz\n  Downloading graphviz-0.15-py2.py3-none-any.whl (18 kB)\nCollecting pyyaml\n  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n\u001B[K     |████████████████████████████████| 269 kB 95.7 MB/s \n\u001B[?25hBuilding wheels for collected packages: retrying, wget, future, pyyaml\n  Building wheel for retrying (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=9530 sha256=9fdc70313da16dc12d3372e566b0b2a2767071e7ad27eba816ee7a9453daa3f9\n  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n  Building wheel for wget (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=11569 sha256=2bc1b3881af802e8e440045c86d3b071fe5c32cfa75e2f9bd2fb59965b1c80b7\n  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n  Building wheel for future (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=493275 sha256=c05002758783879ea02093f213a6766005a626c9ddb830a83ed34003d7985178\n  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n  Building wheel for pyyaml (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=45920 sha256=7c4445b2c8c22200e878251d653e9cfca11f764e9746234bbe379899773f5cd9\n  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\nSuccessfully built retrying wget future pyyaml\nInstalling collected packages: six, numpy, threadpoolctl, scipy, retrying, pytz, python-dateutil, pyparsing, Pillow, kiwisolver, joblib, cycler, wheel, scikit-learn, pyyaml, plotly, pandas, matplotlib, graphviz, future, wget, tqdm, torch, seaborn, lightgbm, datatable, dask, catboost\nSuccessfully installed Pillow-6.2.2 catboost-0.24.3 cycler-0.10.0 dask-2020.12.0 datatable-0.11.1 future-0.18.2 graphviz-0.15 joblib-1.0.0 kiwisolver-1.3.1 lightgbm-3.1.1 matplotlib-3.3.3 numpy-1.19.4 pandas-1.1.5 plotly-4.14.1 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 retrying-1.3.3 scikit-learn-0.23.2 scipy-1.5.4 seaborn-0.11.0 six-1.15.0 threadpoolctl-2.1.0 torch-1.6.0 tqdm-4.53.0 wget-3.2 wheel-0.36.2\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting pip\n  Using cached pip-20.3.3-py2.py3-none-any.whl (1.5 MB)\nInstalling collected packages: pip\nSuccessfully installed pip-20.3.3\n\u001B[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001B[0m\nCollecting Pillow==6.2.2\n  Using cached Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\nCollecting torch==1.6.0\n  Using cached torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\nCollecting tqdm==4.53\n  Using cached tqdm-4.53.0-py2.py3-none-any.whl (70 kB)\nCollecting catboost\n  Using cached catboost-0.24.3-cp37-none-manylinux1_x86_64.whl (66.1 MB)\nCollecting numpy\n  Using cached numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\nCollecting pandas\n  Using cached pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\nCollecting python-dateutil>=2.7.3\n  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting pytz>=2017.2\n  Using cached pytz-2020.4-py2.py3-none-any.whl (509 kB)\nCollecting six\n  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting dask\n  Using cached dask-2020.12.0-py3-none-any.whl (884 kB)\nCollecting datatable\n  Using cached datatable-0.11.1-cp37-cp37m-manylinux2010_x86_64.whl (83.9 MB)\nCollecting lightgbm\n  Using cached lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\nCollecting scikit-learn!=0.22.0\n  Using cached scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\nCollecting joblib>=0.11\n  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\nCollecting scipy\n  Using cached scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\nCollecting threadpoolctl>=2.0.0\n  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\nCollecting matplotlib\n  Using cached matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\nCollecting cycler>=0.10\n  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nCollecting kiwisolver>=1.0.1\n  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\nCollecting plotly\n  Using cached plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\nCollecting retrying>=1.3.3\n  Using cached retrying-1.3.3-py3-none-any.whl\nCollecting pyarrow\n  Downloading pyarrow-0.17.1-cp37-cp37m-manylinux2014_x86_64.whl (63.8 MB)\n\u001B[K     |████████████████████████████████| 63.8 MB 71 kB/s \n\u001B[?25hCollecting seaborn\n  Using cached seaborn-0.11.0-py3-none-any.whl (283 kB)\nCollecting wget\n  Using cached wget-3.2-py3-none-any.whl\nCollecting wheel\n  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting future\n  Using cached future-0.18.2-py3-none-any.whl\nCollecting graphviz\n  Using cached graphviz-0.15-py2.py3-none-any.whl (18 kB)\nCollecting pyyaml\n  Using cached PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: six, numpy, threadpoolctl, scipy, retrying, pytz, python-dateutil, pyparsing, Pillow, kiwisolver, joblib, cycler, wheel, scikit-learn, pyyaml, plotly, pandas, matplotlib, graphviz, future, wget, tqdm, torch, seaborn, pyarrow, lightgbm, datatable, dask, catboost\nSuccessfully installed Pillow-6.2.2 catboost-0.24.3 cycler-0.10.0 dask-2020.12.0 datatable-0.11.1 future-0.18.2 graphviz-0.15 joblib-1.0.0 kiwisolver-1.3.1 lightgbm-3.1.1 matplotlib-3.3.3 numpy-1.19.4 pandas-1.1.5 plotly-4.14.1 pyarrow-0.17.1 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 retrying-1.3.3 scikit-learn-0.23.2 scipy-1.5.4 seaborn-0.11.0 six-1.15.0 threadpoolctl-2.1.0 torch-1.6.0 tqdm-4.53.0 wget-3.2 wheel-0.36.2\nok\n"}],"execution_count":153},{"cell_type":"code","source":"#!M\nimport numpy as np\nimport pandas as pd\nimport pyarrow\nfrom collections import defaultdict\nimport datatable as dt\nimport lightgbm as lgb\n\nfrom catboost.utils import get_gpu_device_count\nfrom catboost import CatBoostClassifier, Pool\n\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n# import riiideducation\nimport torch\nimport pickle\nimport gc\nfrom pathlib import Path\n\n# Error handling, ignore all\nnp.seterr(divide = 'ignore', invalid = 'ignore')\n\nprint(f\"pyarrow {pyarrow.__version__}\")\nprint(f\"curdir {Path.cwd()}\")","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":2.195965,"end_time":"2020-11-23T16:46:37.127434","exception":false,"start_time":"2020-11-23T16:46:34.931469","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"t3n208wi88qtuu9cu40m","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"pyarrow 2.0.0\ncurdir /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/riiidNew\n"}],"execution_count":135},{"cell_type":"code","source":"#!M\n\n# Data config\n\ndtypes = {\n    'row_id': 'int64',\n    'timestamp': 'int64',\n    'user_id': 'int32', \n    'content_id': 'int16', \n    'content_type_id': 'int8',\n    'task_container_id': 'int16',\n    'answered_correctly': 'int8', \n    'prior_question_elapsed_time': 'float32', \n    'prior_question_had_explanation': 'bool',\n    'user_answer': 'int8',\n}\n\ntarget = 'answered_correctly'\n\nhomedir = Path.home()\nprint(str(homedir))\n\nif str(homedir) == \"/home/sergey\":   # Home computer\n    kaggle_path = Path.cwd()/'kaggle_tmp'\n    questions_df = pd.read_csv('/mnt/data30G/2020riid/questions.csv', usecols = [0, 3],\n                               dtype = {'question_id': 'int16', 'part': 'int8'})\n    print(questions_df.head())\n    questions_df.set_index(keys=\"question_id\", inplace=True)\n    questions_df.index.names = [\"content_id\"]\n    print(questions_df.head())\n    # train_df = dt.fread('../input/riiid-test-answer-prediction/train.csv', columns = set(dtypes.keys())).to_pandas()\n    # train_df = dt.fread('/mnt/data30G/2020riid/train.csv', columns = set(dtypes.keys())).to_pandas()\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train_1e5.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid.feather\", columns=dtypes.keys())\n\nelif str(homedir) == \"/root\":   # Datasphere\n    \n    path = Path.cwd()/\"riiidNew\"/\"data\"\n    kaggle_path = Path.cwd()/\"riiidNew\"/\"kaggle\"\n    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n    questions_df.set_index(keys=\"question_id\", inplace=True)\n    questions_df.index.names = [\"content_id\"]\n#     train_df = pd.read_feather(path/\"cv1_train_1e5.feather\", columns=dtypes.keys())\n#     test_df = pd.read_feather(path/\"cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(path/\"data/cv1_valid_1e4.feather\", columns=dtypes.keys())\n    # train_df = pd.read_feather(path/\"cv1_train.feather\", columns=dtypes.keys())\n    # test_df = pd.read_feather(path/\"cv1_valid.feather\", columns=dtypes.keys())\n    # train_df = dt.fread(path/'train.csv', columns=dtypes.keys()).to_pandas().astype(dtypes, errors=\"ignore\")\n    train_df = pd.read_pickle(path/\"cv1_train.pickle.zip\").astype(dtypes, errors=\"ignore\")\n    # train_df = train_df.iloc[:int(1e6)]\n    # test_df = pd.read_pickle(path/\"cv1_valid.pickle.zip\").astype(dtypes, errors=\"ignore\")\n    # test_df = test_df.iloc[:int(1e4)]\n\nprint(f\"train_df shape = {train_df.shape}\")\ntrain_df.head()","metadata":{"papermill":{"duration":0.019374,"end_time":"2020-11-23T16:46:37.206927","exception":false,"start_time":"2020-11-23T16:46:37.187553","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"2w1su8za30ahv2yfmd5kho","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"/home/sergey\n   question_id  part\n0            0     1\n1            1     1\n2            2     1\n3            3     1\n4            4     1\n            part\ncontent_id      \n0              1\n1              1\n2              1\n3              1\n4              1\ntrain_df shape = (100000, 10)\n"},{"output_type":"display_data","data":{"text/plain":"     row_id  timestamp    user_id  content_id  content_type_id  \\\n0  32933156          0  705741139         128                0   \n1  32933157      20666  705741139        7860                0   \n2  32933158      39172  705741139        7922                0   \n3  32933159      58207  705741139         156                0   \n4  32933160      75779  705741139          51                0   \n\n   task_container_id  answered_correctly  prior_question_elapsed_time  \\\n0                  0                   1                          NaN   \n1                  1                   1                      16000.0   \n2                  2                   1                      19000.0   \n3                  3                   1                      17000.0   \n4                  4                   1                      17000.0   \n\n   prior_question_had_explanation  user_answer  \n0                            <NA>            0  \n1                           False            0  \n2                           False            1  \n3                           False            2  \n4                           False            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>answered_correctly</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>user_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32933156</td>\n      <td>0</td>\n      <td>705741139</td>\n      <td>128</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>&lt;NA&gt;</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32933157</td>\n      <td>20666</td>\n      <td>705741139</td>\n      <td>7860</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16000.0</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32933158</td>\n      <td>39172</td>\n      <td>705741139</td>\n      <td>7922</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>19000.0</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32933159</td>\n      <td>58207</td>\n      <td>705741139</td>\n      <td>156</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>17000.0</td>\n      <td>False</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32933160</td>\n      <td>75779</td>\n      <td>705741139</td>\n      <td>51</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>17000.0</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":136},{"cell_type":"markdown","source":"* Information of the training dataset","metadata":{"papermill":{"duration":0.020594,"end_time":"2020-11-23T16:47:42.496580","exception":false,"start_time":"2020-11-23T16:47:42.475986","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"vk8q857fkbl0ou00kw2wqoe"}},{"cell_type":"code","source":"#!M\nsep = '*' * 50\nprint(f'Training dataset detailed information \\n{sep}')\nprint(f'Columns: {train_df.columns} \\n{sep}')\nprint(f'Shape: {train_df.shape} \\n{sep}')\nprint(f'NA values in each column: {sum(train_df.isna().sum())} \\n{sep}')\n\n\ndef prep_data(df, questions_df=questions_df, dtypes=dtypes):\n    # Exclude lectures\n    df = df[df[target] != -1].reset_index(drop=True, inplace=False)\n    # Fill NaN values in the 'prior_question_had_explanation' columns\n    df['prior_question_had_explanation'].fillna(False, inplace=True)\n\n    # Set type\n    df = df.astype(dtypes)\n    \n    # Answer for the previous questions of users\n    df['lag'] = df.groupby('user_id')[target].shift()\n    # For each user (groupby('user_id')), compute the cummulative number of correct answers and number answers in general\n    groupby = df.groupby('user_id')['lag']\n    cum = groupby.agg(['cumsum', 'cumcount'])\n\n    # User correctness (measure the users' learning progress)\n    df['user_correctness'] = cum['cumsum'] / cum['cumcount']\n    # Drop the 'lag' feature\n    df.drop(columns=['lag'], inplace=True)\n    df.head()    \n    \n    # Overall correctness of users\n    user_agg = df.groupby('user_id')[target].agg(['sum', 'count'])\n    # Overall difficulty of questions\n    content_agg = df.groupby('content_id')[target].agg(['sum', 'count'])    \n\n    # Take only 24 last observations of each user\n    df = df.groupby('user_id').tail(24).reset_index(drop=True)\n    \n    df = df.join(questions_df, on='content_id' )\n    # df = pd.merge(df, questions_df, left_on='content_id', right_on='question_id', how='left')\n    # df.drop(columns=['question_id'], inplace=True)\n\n    # How many questions have been answered in each content ID?\n    df['content_count'] = df['content_id'].map(content_agg['count']).astype('int32')\n    # How hard are questions in each content ID?\n    df['content_difficalty'] = df['content_id'].map(content_agg['sum'] / content_agg['count'])\n    # df.drop('content_id', inplace=True, axis=1)\n\n    return user_agg, content_agg, df\n    ","metadata":{"pycharm":{"name":"#%%\n"},"cellId":"2682tt4ygfdlfmc4zyeng","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Training dataset detailed information \n**************************************************\nColumns: Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n       'task_container_id', 'answered_correctly',\n       'prior_question_elapsed_time', 'prior_question_had_explanation',\n       'user_answer'],\n      dtype='object') \n**************************************************\nShape: (100000, 10) \n**************************************************\nNA values in each column: 5347 \n**************************************************\n"}],"execution_count":137},{"cell_type":"markdown","source":"# Extract the validation set","metadata":{"papermill":{"duration":0.021183,"end_time":"2020-11-23T16:48:53.873557","exception":false,"start_time":"2020-11-23T16:48:53.852374","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"hvfpq2wdqaf1hr8xwrqf4q"}},{"cell_type":"code","source":"#!M\ntrain_user_agg, train_content_agg, train_df = prep_data(train_df)\n\n# user_sum_dict = train_user_agg['sum'].astype('int16').to_dict(defaultdict(int))\n# user_count_dict = train_user_agg['count'].astype('int16').to_dict(defaultdict(int))\n# content_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n# content_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n# gc.collect()\n\n\n# Ratio is 6/24 = 25%\nvalid_df = train_df.groupby('user_id').tail(6)\ntrain_df.drop(valid_df.index, inplace = True)","metadata":{"papermill":{"duration":3.111291,"end_time":"2020-11-23T16:48:58.928890","exception":false,"start_time":"2020-11-23T16:48:55.817599","status":"completed"},"tags":[],"cellId":"s0e18onkl9mn8yt7bhussl","trusted":true},"outputs":[],"execution_count":138},{"cell_type":"markdown","source":"# Training","metadata":{"papermill":{"duration":0.023143,"end_time":"2020-11-23T16:48:58.975838","exception":false,"start_time":"2020-11-23T16:48:58.952695","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"suwfns3lzdchqhn90tmrsi"}},{"cell_type":"code","source":"#!L\n# features = ['content_difficalty', \"content_id\", 'prior_question_elapsed_time',\n#             'prior_question_had_explanation', 'user_correctness',\n#             'part', 'content_count']\n\nfeatures = ['content_difficalty', 'user_id', 'prior_question_elapsed_time',\n            'prior_question_had_explanation', 'user_correctness',\n            'part', 'content_count']\n\nparams = {\n    'loss_function': 'Logloss',\n    'eval_metric': 'AUC',\n    'custom_metric': 'AUC:hints=skip_train~false',\n\n    'task_type': 'CPU',  # 'GPU' if get_gpu_device_count() > 0 else 'CPU',\n    # 'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n    'grow_policy': 'Lossguide',\n    'iterations': 2,\n    'learning_rate': 4e-3,\n    'random_seed': 0,\n    'l2_leaf_reg': 5e-1,\n    'depth': 10,\n    #'rsm': 0.3,\n    # 'max_leaves': 10,\n    'border_count': 128,\n    'verbose': 150,\n    'od_type': 'Iter',\n    'od_wait': 50,\n}\nprint(params)\n\n# Training and validating data\ntrain_set = Pool(train_df[features], label = train_df[target])\nval_set = Pool(valid_df[features], label = valid_df[target])\n# val_set = Pool(test_df[features], label = test_df[target])\n\n# Model definition\nmodel = CatBoostClassifier(**params)\n\n# Fitting\nmodel.fit(train_set, eval_set = val_set, use_best_model = True)\nprint(f\"kaggle_path {kaggle_path}\")\n\nmodel.save_model(str(kaggle_path/'catboost.model'))","metadata":{"papermill":{"duration":207.603145,"end_time":"2020-11-23T16:52:31.347675","exception":false,"start_time":"2020-11-23T16:49:03.744530","status":"completed"},"tags":[],"cellId":"o8jdczcyj1h3jkjzlxzy9w","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': 'AUC:hints=skip_train~false', 'task_type': 'CPU', 'grow_policy': 'Lossguide', 'iterations': 2, 'learning_rate': 0.004, 'random_seed': 0, 'l2_leaf_reg': 0.5, 'depth': 10, 'border_count': 128, 'verbose': 150, 'od_type': 'Iter', 'od_wait': 50}\n0:\tlearn: 0.7758269\ttest: 0.7631521\tbest: 0.7631521 (0)\ttotal: 35.7ms\tremaining: 35.7ms\n1:\tlearn: 0.7812295\ttest: 0.7702233\tbest: 0.7702233 (1)\ttotal: 63.3ms\tremaining: 0us\n\nbestTest = 0.7702233275\nbestIteration = 1\n\nkaggle_path /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/riiidNew/kaggle_tmp\n"}],"execution_count":139},{"cell_type":"markdown","source":"\n{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'task_type': 'GPU', 'grow_policy': 'Lossguide', 'iterations': 15000, 'learning_rate': 0.01, 'random_seed': 0, 'l2_leaf_reg': 0.1, 'depth': 8, 'border_count': 128, 'verbose': 150, 'od_type': 'Iter', 'od_wait': 50}\nbestTest = 0.7371392846\n\nbestTest = 0.7370638549\nbestTest = 0.7364509702\n","metadata":{"cellId":"nl7v0tm6byjfdfngg11ydh"}},{"cell_type":"code","source":"model.get_best_score()","metadata":{"cellId":"c1pc7wh24o8ipu8gk23jbh","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"{'learn': {'Logloss': 0.6912894493875078, 'AUC': 0.7812294949729874},\n 'validation': {'Logloss': 0.6914273813025933, 'AUC': 0.7702233274556736}}"},"metadata":{}}],"execution_count":140},{"cell_type":"code","source":"train_df.head()\ndel train_df\ngc.collect()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"p79bpqc73j5stkg5k8i03"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.051177,"end_time":"2020-11-23T16:52:31.451640","exception":false,"start_time":"2020-11-23T16:52:31.400463","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"},"cellId":"ba4wdwyypnjxlgzfd769b9"}},{"cell_type":"code","source":"#!M\nmean_dict = {\n    'user_sum_dict': train_user_agg['sum'].astype('int16').to_dict(defaultdict(int)),\n    'user_count_dict': train_user_agg['count'].astype('int16').to_dict(defaultdict(int)),\n    'content_sum_dict': train_content_agg['sum'].astype('int32').to_dict(defaultdict(int)),\n    'content_count_dict': train_content_agg['count'].astype('int32').to_dict(defaultdict(int)),\n\n}\n\n# for filename, dic in mean_dict.items():\n#     with open(f'{kaggle_path}/{filename}.pickle', 'wb') as handle:\n#         pickle.dump(dic, handle)\n\n# with open(f\"{kaggle_path/'mean_dict.pickle'}\", 'wb') as handle:\n#     pickle.dump(mean_dict, handle)","metadata":{"papermill":{"duration":0.618845,"end_time":"2020-11-23T16:52:32.122494","exception":false,"start_time":"2020-11-23T16:52:31.503649","status":"completed"},"tags":[],"pycharm":{"name":"#%%\n"},"cellId":"7ui7ur3vc7044m7d88w7h2","trusted":true},"outputs":[],"execution_count":142},{"cell_type":"code","source":"user_df = pd.DataFrame(data={\n    'sum_': train_user_agg['sum'].astype('int32'),\n    'count_': train_user_agg['count'].astype('int32')\n})\nprint(\"user_df\")\nuser_df.head()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"e41fediehdn7e1k825"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"content_df = pd.DataFrame(data={\n    'sum_': train_content_agg['sum'].astype('int32'),\n    'count_': train_content_agg['count'].astype('int32')\n})\nprint(\"content_df\")\ncontent_df.head()\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"jhyil2vrgol52frfq32aev"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n\ntest_user_agg, test_content_agg, test_df = prep_data(test_df)\nprint(test_df.columns)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"2b9kglioa7fskye1w4cxys"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.drop(labels=['user_correctness', 'content_count', 'content_difficalty'], axis=1, inplace=True)\ngc.collect()\n\ntest_df.head()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"8rpu9tplgbd0ia9bj1933pm"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nvalidaten_flg = True\nif validaten_flg:\n    from emulator import Iter_Valid\n    iter_test = Iter_Valid(test_df,max_user=1000)\n    predicted = []\n    def set_predict(df):\n        predicted.append(df)\nelse:\n    import riiideducation\n    env = riiideducation.make_env()\n    iter_test = env.iter_test()\n    set_predict = env.predict","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"e03sxt9mfraiqacsynbmz"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cumcount = sum([len(df) for df in predicted])\n# count = 0\n# pbar = tqdm(total=cumcount)\n# previous_test_df = None\n# for (current_test, current_prediction_df) in iter_test:\n#     count+=1\n#     if previous_test_df is not None:\n#         answers = eval(current_test[\"prior_group_answers_correct\"].iloc[0])\n#         responses = eval(current_test[\"prior_group_responses\"].iloc[0])\n#         previous_test_df['answered_correctly'] = answers\n#         previous_test_df['user_answer'] = responses\n#         # your feature extraction and model training code here\n#     previous_test_df = current_test.copy()\n#     current_test = current_test[current_test.content_type_id == 0]\n#     # your prediction code here\n#     current_test['answered_correctly'] = model.predict(current_test[features])  # 0.5\n#     set_predict(current_test.loc[:,['row_id', 'answered_correctly']])\n#     pbar.update(len(current_test))\n# print(f\"count {count} {len(predicted)}\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"qtuzam6jvoy8usuu8vcp"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nprior_test_df = None\ncount = 0\nfor (test_df, sample_prediction_df) in iter_test:\n    print(\"count loop starting\", count)\n\n    if prior_test_df is not None:\n\n        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n\n        prior_user_id_idx = prior_test_df.index.get_level_values(\"user_id\")\n        content_id_idx = prior_test_df.index.get_level_values(\"content_id\")\n\n        new_users = prior_test_df.loc[~prior_user_id_idx.isin(user_df.index)]\n        new_user_id_idx = new_users.index.get_level_values(\"user_id\").drop_duplicates()\n\n        if len(new_users) > 0:\n            new_users_df = pd.DataFrame(data=0, index=new_user_id_idx, columns=user_df.columns, )\n            user_df = user_df.append(new_users_df, sort=True)\n\n        user_df.sum_ = \\\n            user_df.sum_.add(prior_test_df[target], fill_value=0, level=\"user_id\")\n        #\n        # user_df.count_ = \\\n        #     user_df.count_.add(1, fill_value=0, level=\"user_id\")\n        #\n        # content_df.sum_ = \\\n        #     content_df.sum_.add(prior_test_df[target], fill_value=0, level=\"content_id\")\n        #\n        # content_df.count_ = \\\n        #     user_df.count_.add(1, fill_value=0, level=\"content_id\")\n\n\n    test_df = test_df[test_df['content_type_id'] == 0]  # .reset_index(drop=True)\n    test_df.set_index([\"user_id\", \"content_id\"], inplace=True)\n    prior_test_df = test_df.copy()\n\n    test_df.drop(labels=\"part\", axis=1, inplace=True)\n\n    if count > 1:\n        print(test_df.index.is_unique)\n    test_df = test_df.join(questions_df, how='left')\n\n    user_correctness = pd.Series(data=(user_df.sum_ / user_df.count_).values, name=\"user_correctness\")\n    user_correctness.index.names = [\"user_id\"]\n\n    content_difficalty = pd.Series(data=(content_df.sum_ / content_df.count_).values, name=\"content_difficalty\")\n    content_difficalty.index.names = [\"content_id\"]\n\n    content_count = pd.Series(data=content_df.count_.values, name=\"content_count\")\n    content_count.index.names = [\"content_id\"]\n\n    test_df = test_df.join(content_count)\n    test_df = test_df.join(content_difficalty)\n    test_df = test_df.join(user_correctness)\n\n    test_df.reset_index(inplace=True)\n\n    test_df[target] = model.predict_proba(test_df[features])[:,1]\n    set_predict(test_df[['row_id', target]])\n\n    print(\"count loop finished\", count)\n    count += 1","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"ig75ftdfwsk3u2hpcerrz4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%time\n#\n# prior_test_df = None\n# count = 0\n# for (test_df, sample_prediction_df) in iter_test:\n#     if prior_test_df is not None:\n#         prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n#         prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop = True)\n#\n#         # user_ids = prior_test_df['user_id'].values\n#         # content_ids = prior_test_df['content_id'].values\n#         # targets = prior_test_df[target].values\n#\n#         for idx, (user_id, content_id, target) in prior_test_df[[\"user_id\", \"content_id\", target]].iterrows():\n#         # for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n#             mean_dict['user_sum_dict'][user_id] += target\n#             mean_dict['user_count_dict'][user_id] += 1\n#             mean_dict['content_sum_dict'][content_id] += target\n#             mean_dict['content_count_dict'][content_id] += 1\n#\n#     if count < 1:\n#         print(type(mean_dict['user_sum_dict']))\n#         # mean_df = pd.DataFrame.from_dict(mean_dict['user_sum_dict'])\n#         count = 1\n#         # print(mean_df)\n#\n#     prior_test_df = test_df.copy()\n#\n#     test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n#     test_df.drop(labels=\"part\", axis=1, inplace=True)\n#     test_df.content_id = test_df.content_id.astype(int)\n#\n#     test_df = pd.merge(test_df, questions_df, left_on = 'content_id',\n#                        right_on = 'question_id', how = 'left', right_index=True)\n#     test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')\n#\n#     user_sum = np.zeros(len(test_df), dtype = np.int16)\n#     user_count = np.zeros(len(test_df), dtype = np.int16)\n#     content_sum = np.zeros(len(test_df), dtype = np.int32)\n#     content_count = np.zeros(len(test_df), dtype = np.int32)\n#\n#     # \"for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n#     for i, (user_id, content_id) in test_df[['user_id', 'content_id']].iterrows():\n#         user_sum[i] = mean_dict['user_sum_dict'][user_id]\n#         user_count[i] = mean_dict['user_count_dict'][user_id]\n#         content_sum[i] = mean_dict['content_sum_dict'][content_id]\n#         content_count[i] = mean_dict['content_count_dict'][content_id]\n#\n#     test_df['user_correctness'] = user_sum / user_count\n#     test_df['content_count'] = content_count\n#     test_df['content_id'] = content_sum / content_count\n#\n#     test_df[target] = model.predict_proba(test_df[features])[:,1]\n#     set_predict(test_df[['row_id', target]])\n#","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"df26uxod32o37bfmlmzidt"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"len(predicted)\", len(predicted))\n\nprint(predicted[0])","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"twg8svfsjv78rajoccdc8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.shape","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"wlox0przm49encxhsj8a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"cellId":"7dtjgytnqm75998i8i0thh"},"outputs":[],"execution_count":null}]}