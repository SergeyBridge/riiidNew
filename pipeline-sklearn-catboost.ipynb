{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Yandex DataSphere Kernel",
   "language": "python"
  },
  "language_info": {
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "file_extension": ".py",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python"
  },
  "papermill": {
   "duration": 392.708184,
   "end_time": "2020-11-23T16:52:33.291774",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T16:46:00.583590",
   "version": "2.1.0"
  },
  "notebookId": "49f1538a-c226-4642-b21c-95b4d1717f3e"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "# !pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n",
    "# %pip install --upgrade pip\n",
    "# %pip install -r /home/jupyter/work/resources/riiidNew/requirements.txt --upgrade\n",
    "# print(\"ok\")\n"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 30.191831,
     "end_time": "2020-11-23T16:46:34.873724",
     "exception": false,
     "start_time": "2020-11-23T16:46:04.681893",
     "status": "completed"
    },
    "tags": [],
    "cellId": "r4gbiatk8h938d934p4aip",
    "trusted": true
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# \"https://docs-python.ru/tutorial/operatsii-slovarjami-dict-python/metod-dict-update/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Взято из репозитория\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from collections import defaultdict\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from catboost.utils import get_gpu_device_count\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# import riiideducation\n",
    "import torch\n",
    "import pickle\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from preprocess import preprocess_train_data  # , catboost_hyperparams\n",
    "from torch import cuda\n",
    "\n",
    "\n",
    "\n",
    "# Error handling, ignore all\n",
    "np.seterr(divide = 'ignore', invalid = 'ignore')\n",
    "\n",
    "print(f\"pyarrow {pyarrow.__version__}\")\n",
    "print(f\"curdir {Path.cwd()}\")\n"
   ],
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 2.195965,
     "end_time": "2020-11-23T16:46:37.127434",
     "exception": false,
     "start_time": "2020-11-23T16:46:34.931469",
     "status": "completed"
    },
    "tags": [],
    "cellId": "t3n208wi88qtuu9cu40m",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n.datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAYAAADuMJi0AAAGR0lEQVR42rVZ21IbRxBtCbQrkIR2dQVjsLmDLBsET3nTQ8ouYRkQVf6e/E9+Im958qMfkgoXAaKSSj6C9Jnd2R2NeiRSRaZqitVOT5+Z6dNnWoKGlN94JFp8Ipofkb/7SOXjGyp8wF+z35K3f0uUp/GW4XfLQ8v2gefj3ZCCzojoNfue+43o1Q3l3xB/yA3JO7jnF2pCLnI+pNyx/qw7L+SQ7T2N9p2f8c60QcfcK6KGXsAd+ZvA4LlZYuSSAoOhMs5vwJkEGDlbPMaJoA+FcQ0IH38QLWkbAFLkOOhoMF5tU6/eBRhNjro0ZgKiPRAt3FLhCO/vqdgmNTm32LkmKpvBmQY4q5uAaAgbwDBG2BVv3bfI8KKAMWj2kfw9+pkZREIbEql4ST1x7hgHIANkbJ//MF8mAH/ilTCJ2tIi4ASr1IC3VNqXHKOxjy34mgoImnOQtx1g81fkqTiMOBVGcTogNhiT5iBHET8R8C+iApJUmgim3SQAXhsLQz7ee2G8gOAQNtJckBEplADiAxtX+G9NmhDl0qJKnTvyWlAMPYZnvIviGXRg6/Dh824DBXhP/tbfREXJEIvQ+aaPGjG7pvw6r3xdx+9hqb4dgZaP2XmdHO2K/B0c1+oUph6k8kShBryl/Ft0DYgjTlOieOACHFFpVyUl72T9V3cM1jUoYvxIC2vpCSys/ck70mDYuYvdvKjlMdKAUThneWVU1aAsyjv6PURDiwNsHGBZzY+JtAAgE2TFxdRHJdyIp/f+zqu09M5cDP2F08Ukkpj4YNSdX950HY2pNCCUK/Hhx5ZMBfjNSEzdsIihVzzAMdn9dz4eDYhnyQb9SSCiAryiJcQk82LiTbJ4x2FZJaUenpKnzP95WyDf4Y+QN9EFHHSeDLGdBjjKNQ5vKHf4XMA7KrY0y0GEObBOO/8e1ywuQExOHXktuQyJALEBpcEqhwtHqgiDuCK5b6i0p2MQpcckIIoh+6hYgTZtO8xlMi6O4tKCF/kOGHEg/W0UUpHW0ZoGNZ1ExZWcn7EErgwt4uj50E/sFBjXXIayWvh7WryjasxarZKssXon0zxvvkc32Q0bqbBCuZiKt9dWFysfQefeL29JYFaeztX6tePaZdz5mYx8+6Zq3Mk0wXECQxlhdzgS2wjBHju3j1RIgKyOMdNUE8X0+RAdbSapS11MRCv1SzUXmO6wGZe2SQYrv2MvCSWEv2VODE6DN7bz8ufypgQKW7uQskFTQHULLKyaEyrnlZbgOGLrV5qrn9U79jjm2HJmgkaVN98AfBub91lGPLZBqdroN5LYgjSu4zYZDDHXZOIPC691HqrWI1900I8qLzgKP4ft8DxEWigprPfrO+KcXno9gZz4jjGewWdUcpGCj0qVFuGPYbl2VturndZ2qRvlL8acDO6lF/DY/VjsFesiUK+ypJ+r/ep+cJkSQxEK4PG4WozgA75TYrDDqStE69K8/mzGEM+JXTeqvmedEElMmwCMm2SLd6bNNF9su02zEtoW6nAQtpMj5Gd7fKa//wqonF7UdtHFsVn+6hf1o7AfriPH7M6EeIUEF5zKVxXbYo7kS/OEtOqDYZKPoBsETIixn0uYrasThmzDkhdKPkz2EnaX0HdQbIgr59vAdGYDqjHrxkjS7WOxkTD8sqEqhiwcJETgBYigrBqF08KyDaje9SZ/I1A7MzaTzMGDEulPtZUkuKcyIRAjxEJPVrnVlb/9wkfij31D/pQt1IN+iL8bGJcstBIO7Y5VI/cwDqURbXhMuJxBqD0KLoK3esWFs0Jz5i5ZvJUAfFJMFb9XmGIOnzGpijpcWYCaMqXSQWp8EnCABepQ0Elyi4wfKfsw78ikIqif1pe1AGPlLmojl1SKxHHXp1L+Ut7AmDQHvhI5xHGi4EooO2BR7k78PEkJOdL7cAxQUZ/Tyclu9gnfwGgOmm2lNHGNmZXsq4Pqgc1EG1ATrvKl8s4R9ywwnqulGUnaRLVhxy8v3ieUwy2hbooT68uscW++DCDH0WSzuoyN2D4LUJ/tLECbcSKznwMIFs0ChF4mRTCnQbIIfk4SHJo6A9BMuTnXTs3Ku/KxsgZWqzuSe+Os8cEUfnMBY6UF5gi3SUbd5K7vDjq5WW0UENJlRsWn4sy21Er/E/AvPQSFHy1p4fgAAAAASUVORK5CYII=');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow 2.0.0\n",
      "curdir /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/riiidNew\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "\n",
    "# Data config\n",
    "\n",
    "dtypes = {\n",
    "    'row_id': 'int64',\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32', \n",
    "    'content_id': 'int16', \n",
    "    'content_type_id': 'int8',\n",
    "    'task_container_id': 'int16',\n",
    "    'answered_correctly': 'int8', \n",
    "    'prior_question_elapsed_time': 'float32', \n",
    "    'prior_question_had_explanation': 'bool',\n",
    "    'user_answer': 'int8',\n",
    "}\n",
    "\n",
    "target = 'answered_correctly'\n",
    "\n",
    "homedir = Path.home()\n",
    "print(str(homedir))\n",
    "\n",
    "if str(homedir) == \"/home/sergey\":   # Home computer\n",
    "    kaggle_path = Path.cwd()/\"kaggle_tmp/\"\n",
    "    questions_df = pd.read_csv('/mnt/data30G/2020riiid/questions.csv', usecols = [0, 3], dtype = {'question_id': 'int32', 'part': 'int32'})\n",
    "    # train_df = dt.fread('../input/riiid-test-answer-prediction/train.csv', columns = set(dtypes.keys())).to_pandas()\n",
    "    # train_df = dt.fread('/mnt/data30G/2020riid/train.csv', columns = set(dtypes.keys())).to_pandas()\n",
    "    test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train_1e5.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # train_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_train.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(\"/home/sergey/mnt/4.5Tb/Downloads/riiidCVdata/cv1_valid.feather\", columns=dtypes.keys())\n",
    "\n",
    "elif str(homedir) == \"/root\":   # Datasphere\n",
    "    \n",
    "    path = Path.cwd()/\"riiidNew\"/\"data\"\n",
    "    kaggle_path = Path.cwd()/\"riiidNew\"/\"kaggle/\"\n",
    "    # questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int16', 'part': 'int8'})\n",
    "    questions_df = pd.read_csv(path/'questions.csv', usecols = [0, 3], dtype = {'question_id': 'int32', 'part': 'int32'})\n",
    "#     train_df = pd.read_feather(path/\"cv1_train_1e5.feather\", columns=dtypes.keys())\n",
    "#     test_df = pd.read_feather(path/\"cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(path/\"data/cv1_valid_1e4.feather\", columns=dtypes.keys())\n",
    "    # train_df = pd.read_feather(path/\"cv1_train.feather\", columns=dtypes.keys())\n",
    "    # test_df = pd.read_feather(path/\"cv1_valid.feather\", columns=dtypes.keys())\n",
    "    # train_df = dt.fread(path/'train.csv', columns=dtypes.keys()).to_pandas().astype(dtypes, errors=\"ignore\")    \n",
    "    train_df = pd.read_pickle(path/\"cv1_train.pickle.zip\").astype(dtypes, errors=\"ignore\")\n",
    "    # train_df = train_df.iloc[:int(1e5)]\n",
    "    test_df = pd.read_pickle(path/\"cv1_valid.pickle.zip\").astype(dtypes, errors=\"ignore\")\n",
    "    # test_df = test_df.iloc[:int(1e4)]\n",
    "\n",
    "print(f\"train_df shape = {train_df.shape}\")"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019374,
     "end_time": "2020-11-23T16:46:37.206927",
     "exception": false,
     "start_time": "2020-11-23T16:46:37.187553",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "2w1su8za30ahv2yfmd5kho",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sergey\n",
      "train_df shape = (100000, 10)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "train_user_agg, train_content_agg, train_df = preprocess_train_data(train_df, questions_df, target, dtypes)\n",
    "test_user_agg, test_content_agg, test_df = preprocess_train_data(test_df, questions_df, target, dtypes)\n",
    "\n",
    "# Ratio is 6/24 = 25%\n",
    "valid_df = train_df.groupby('user_id').tail(6)\n",
    "train_df.drop(valid_df.index, inplace = True)"
   ],
   "metadata": {
    "papermill": {
     "duration": 3.111291,
     "end_time": "2020-11-23T16:48:58.928890",
     "exception": false,
     "start_time": "2020-11-23T16:48:55.817599",
     "status": "completed"
    },
    "tags": [],
    "cellId": "s0e18onkl9mn8yt7bhussl",
    "trusted": true
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "#!L\n",
    "features = ['content_id', 'prior_question_elapsed_time', \n",
    "            'prior_question_had_explanation', 'user_correctness', \n",
    "            'part', 'content_count']\n",
    "\n",
    "# Training and validating data\n",
    "train_set = Pool(train_df[features], label = train_df[target])\n",
    "val_set = Pool(valid_df[features], label = valid_df[target])\n",
    "# val_set = Pool(test_df[features], label = test_df[target])\n",
    "\n",
    "prior_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'custom_metric': 'AUC:hints=skip_train~false',\n",
    "    'task_type': 'CPU',  #  'GPU' if cuda.is_available() else 'CPU',\n",
    "    'grow_policy': 'Lossguide',\n",
    "    'iterations': 2,\n",
    "    'learning_rate': 4e-3,\n",
    "    'random_seed': 0,\n",
    "    'l2_leaf_reg': 4e-3,\n",
    "    'depth': 6,\n",
    "    'border_count': 128,\n",
    "    'verbose': False, # 150,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 50,\n",
    "    'max_leaves': 10,\n",
    "    }\n",
    "\n",
    "\n",
    "pds = {\n",
    "    'l2_leaf_reg': [2e-1, 5e2],\n",
    "    'depth': [6, 15],\n",
    "    'max_leaves': [10, 120],\n",
    "    'border_count': [50, 300],\n",
    "\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 207.603145,
     "end_time": "2020-11-23T16:52:31.347675",
     "exception": false,
     "start_time": "2020-11-23T16:49:03.744530",
     "status": "completed"
    },
    "tags": [],
    "cellId": "o8jdczcyj1h3jkjzlxzy9w",
    "trusted": true
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def bayesian_catboost_searchCV(train_set, pds, init_points=3, n_iter=7):\n",
    "\n",
    "    def catboost_hyperparams(**dict):\n",
    "        params = {'loss_function': 'Logloss',\n",
    "                  'eval_metric': 'AUC',\n",
    "                  'custom_metric': 'AUC:hints=skip_train~false',\n",
    "                  'task_type': 'CPU',  #  'GPU' if cuda.is_available() else 'CPU',\n",
    "                  'grow_policy': 'Lossguide',\n",
    "                  'iterations': 2,\n",
    "                  'learning_rate': 4e-3,\n",
    "                  'random_seed': 0,\n",
    "                  'l2_leaf_reg': dict[\"l2_leaf_reg\"],\n",
    "                  'depth': int(dict[\"depth\"]),\n",
    "                  'border_count': int(dict['border_count']),\n",
    "                  'verbose': False, # 150,\n",
    "                  'od_type': 'Iter',\n",
    "                  'od_wait': 50,\n",
    "                  'max_leaves': int(dict[\"max_leaves\"])\n",
    "                }\n",
    "\n",
    "\n",
    "        # Model definition\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "        # Fitting\n",
    "        scores = catboost.cv(train_set, params,\n",
    "                             plot=False,\n",
    "                             # metric_period=10,\n",
    "                             type='TimeSeries',\n",
    "                             fold_count=3)\n",
    "        # model.fit(train_set, eval_set=val_set, use_best_model=True)\n",
    "\n",
    "        # return np.max(model.get_best_score()[\"validation\"][\"AUC\"])\n",
    "        print(\"scores\", scores)\n",
    "        return np.max(scores[\"test-AUC-mean\"])\n",
    "\n",
    "    optimizer = BayesianOptimization(catboost_hyperparams, pds, random_state=0)\n",
    "    optimizer.maximize(init_points, n_iter)\n",
    "    return optimizer.max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | border... |   depth   | l2_lea... | max_le... |\n",
      "-------------------------------------------------------------------------\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.763959      0.014742        0.756828       0.009946   \n",
      "1           1       0.774311      0.010108        0.768959       0.006142   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692149          0.000186            0.692223           0.000132  \n",
      "1           0.691095          0.000389            0.691238           0.000288  \n",
      "| \u001B[0m 1       \u001B[0m | \u001B[0m 0.7743  \u001B[0m | \u001B[0m 187.2   \u001B[0m | \u001B[0m 12.44   \u001B[0m | \u001B[0m 301.5   \u001B[0m | \u001B[0m 69.94   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.771992      0.012131        0.766738       0.008736   \n",
      "1           1       0.778075      0.007194        0.773278       0.004387   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692011          0.000197            0.692101           0.000125  \n",
      "1           0.690901          0.000327            0.691079           0.000203  \n",
      "| \u001B[95m 2       \u001B[0m | \u001B[95m 0.7781  \u001B[0m | \u001B[95m 155.9   \u001B[0m | \u001B[95m 11.81   \u001B[0m | \u001B[95m 218.9   \u001B[0m | \u001B[95m 108.1   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.768050      0.013323        0.761711       0.010884   \n",
      "1           1       0.777677      0.011373        0.770784       0.008668   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692165          0.000215            0.692227           0.000170  \n",
      "1           0.691076          0.000332            0.691220           0.000252  \n",
      "| \u001B[0m 3       \u001B[0m | \u001B[0m 0.7777  \u001B[0m | \u001B[0m 290.9   \u001B[0m | \u001B[0m 9.451   \u001B[0m | \u001B[0m 395.9   \u001B[0m | \u001B[0m 68.18   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.773711      0.012545        0.767488       0.010030   \n",
      "1           1       0.780607      0.009387        0.774944       0.006928   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692025          0.000223            0.692107           0.000151  \n",
      "1           0.690861          0.000333            0.691025           0.000235  \n",
      "| \u001B[95m 4       \u001B[0m | \u001B[95m 0.7806  \u001B[0m | \u001B[95m 155.9   \u001B[0m | \u001B[95m 13.99   \u001B[0m | \u001B[95m 221.5   \u001B[0m | \u001B[95m 105.4   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.774937      0.008824        0.769456       0.002697   \n",
      "1           1       0.780193      0.008977        0.773997       0.004177   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692002          0.000163            0.692102           0.000091  \n",
      "1           0.690938          0.000241            0.691125           0.000153  \n",
      "| \u001B[0m 5       \u001B[0m | \u001B[0m 0.7802  \u001B[0m | \u001B[0m 163.2   \u001B[0m | \u001B[0m 10.61   \u001B[0m | \u001B[0m 227.0   \u001B[0m | \u001B[0m 106.8   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.771542      0.012531        0.762686       0.009254   \n",
      "1           1       0.777544      0.012150        0.769432       0.008917   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692067          0.000188            0.692158           0.000126  \n",
      "1           0.690978          0.000274            0.691153           0.000186  \n",
      "| \u001B[0m 6       \u001B[0m | \u001B[0m 0.7775  \u001B[0m | \u001B[0m 203.7   \u001B[0m | \u001B[0m 13.71   \u001B[0m | \u001B[0m 417.9   \u001B[0m | \u001B[0m 78.25   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.774506      0.010108        0.769362       0.007125   \n",
      "1           1       0.780917      0.008199        0.776410       0.003986   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692020          0.000192            0.692110           0.000126  \n",
      "1           0.690916          0.000311            0.691087           0.000175  \n",
      "| \u001B[95m 7       \u001B[0m | \u001B[95m 0.7809  \u001B[0m | \u001B[95m 155.7   \u001B[0m | \u001B[95m 9.69    \u001B[0m | \u001B[95m 224.0   \u001B[0m | \u001B[95m 104.0   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.773762      0.009087        0.769034       0.006414   \n",
      "1           1       0.779976      0.008535        0.776478       0.004423   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692051          0.000120            0.692134           0.000077  \n",
      "1           0.690996          0.000328            0.691147           0.000216  \n",
      "| \u001B[0m 8       \u001B[0m | \u001B[0m 0.78    \u001B[0m | \u001B[0m 159.2   \u001B[0m | \u001B[0m 8.696   \u001B[0m | \u001B[0m 221.1   \u001B[0m | \u001B[0m 96.74   \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.768106      0.013423        0.760815       0.008522   \n",
      "1           1       0.775904      0.011614        0.770166       0.005466   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692176          0.000222            0.692250           0.000160  \n",
      "1           0.691165          0.000388            0.691316           0.000288  \n",
      "| \u001B[0m 9       \u001B[0m | \u001B[0m 0.7759  \u001B[0m | \u001B[0m 52.4    \u001B[0m | \u001B[0m 6.53    \u001B[0m | \u001B[0m 407.1   \u001B[0m | \u001B[0m 98.1    \u001B[0m |\n",
      "scores    iterations  test-AUC-mean  test-AUC-std  train-AUC-mean  train-AUC-std  \\\n",
      "0           0       0.772875      0.011644        0.765653       0.008923   \n",
      "1           1       0.777119      0.011409        0.771017       0.010548   \n",
      "\n",
      "   test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
      "0           0.692005          0.000187            0.692098           0.000118  \n",
      "1           0.690937          0.000316            0.691108           0.000230  \n",
      "| \u001B[0m 10      \u001B[0m | \u001B[0m 0.7771  \u001B[0m | \u001B[0m 155.8   \u001B[0m | \u001B[0m 14.07   \u001B[0m | \u001B[0m 234.8   \u001B[0m | \u001B[0m 95.67   \u001B[0m |\n",
      "=========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'target': 0.7809165886816575,\n 'params': {'border_count': 155.6946859118282,\n  'depth': 9.689734696339546,\n  'l2_leaf_reg': 224.03579335985572,\n  'max_leaves': 104.00321450264359}}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"optimizer_maxCV\")\n",
    "optimizer_maxCV = bayesian_catboost_searchCV(train_set, pds=pds, init_points=5, n_iter=7)\n",
    "optimizer_maxCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "exit(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "{'loss_function': 'Logloss', 'eval_metric': 'AUC', 'task_type': 'GPU', 'grow_policy': 'Lossguide', 'iterations': 15000, 'learning_rate': 0.01, 'random_seed': 0, 'l2_leaf_reg': 0.1, 'depth': 8, 'border_count': 128, 'verbose': 150, 'od_type': 'Iter', 'od_wait': 50}\n",
    "bestTest = 0.7371392846\n",
    "\n",
    "bestTest = 0.7370638549\n",
    "bestTest = 0.7364509702"
   ],
   "metadata": {
    "cellId": "nl7v0tm6byjfdfngg11ydh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def bayesian_catboost_search(train_set, val_set, prior_params, pds, init_points=3, n_iter=7):\n",
    "\n",
    "    def catboost_hyperparams(**dict):\n",
    "        # params = prior_params.update(dict)\n",
    "        params = {'loss_function': 'Logloss',\n",
    "                  'eval_metric': 'AUC',\n",
    "                  'custom_metric': 'AUC:hints=skip_train~false',\n",
    "                  'task_type': 'CPU',  #  'GPU' if cuda.is_available() else 'CPU',\n",
    "                  'grow_policy': 'Lossguide',\n",
    "                  'iterations': 2,\n",
    "                  'learning_rate': 4e-3,\n",
    "                  'random_seed': 0,\n",
    "                  'l2_leaf_reg': dict[\"l2_leaf_reg\"],\n",
    "                  'depth': int(dict[\"depth\"]),\n",
    "                  'border_count': int(dict['border_count']),\n",
    "                  'verbose': False, # 150,\n",
    "                  'od_type': 'Iter',\n",
    "                  'od_wait': 50,\n",
    "                  'max_leaves': int(dict[\"max_leaves\"])\n",
    "                }\n",
    "\n",
    "\n",
    "        # Model definition\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "        # Fitting\n",
    "        model.fit(train_set, eval_set=val_set, use_best_model=True)\n",
    "\n",
    "        return np.max(model.get_best_score()[\"validation\"][\"AUC\"])\n",
    "\n",
    "    optimizer = BayesianOptimization(catboost_hyperparams, pds, random_state=0)\n",
    "    optimizer.maximize(init_points, n_iter)\n",
    "    return optimizer.max\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "optimzer_max = bayesian_catboost_search(train_set=train_set, val_set=val_set,\n",
    "                                        prior_params=prior_params, pds=pds,\n",
    "                                        init_points=5, n_iter=7)\n",
    "optimzer_max"
   ],
   "metadata": {
    "cellId": "c1pc7wh24o8ipu8gk23jbh",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | border... |   depth   | l2_lea... | max_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001B[0m 1       \u001B[0m | \u001B[0m 0.7703  \u001B[0m | \u001B[0m 187.2   \u001B[0m | \u001B[0m 12.44   \u001B[0m | \u001B[0m 301.5   \u001B[0m | \u001B[0m 69.94   \u001B[0m |\n",
      "| \u001B[0m 2       \u001B[0m | \u001B[0m 0.7696  \u001B[0m | \u001B[0m 155.9   \u001B[0m | \u001B[0m 11.81   \u001B[0m | \u001B[0m 218.9   \u001B[0m | \u001B[0m 108.1   \u001B[0m |\n",
      "| \u001B[0m 3       \u001B[0m | \u001B[0m 0.7683  \u001B[0m | \u001B[0m 290.9   \u001B[0m | \u001B[0m 9.451   \u001B[0m | \u001B[0m 395.9   \u001B[0m | \u001B[0m 68.18   \u001B[0m |\n",
      "| \u001B[95m 4       \u001B[0m | \u001B[95m 0.7705  \u001B[0m | \u001B[95m 185.4   \u001B[0m | \u001B[95m 6.406   \u001B[0m | \u001B[95m 290.6   \u001B[0m | \u001B[95m 65.7    \u001B[0m |\n",
      "| \u001B[0m 5       \u001B[0m | \u001B[0m 0.7666  \u001B[0m | \u001B[0m 195.2   \u001B[0m | \u001B[0m 12.72   \u001B[0m | \u001B[0m 307.5   \u001B[0m | \u001B[0m 67.59   \u001B[0m |\n",
      "| \u001B[0m 6       \u001B[0m | \u001B[0m 0.7656  \u001B[0m | \u001B[0m 203.7   \u001B[0m | \u001B[0m 13.71   \u001B[0m | \u001B[0m 417.9   \u001B[0m | \u001B[0m 78.25   \u001B[0m |\n",
      "| \u001B[0m 7       \u001B[0m | \u001B[0m 0.7676  \u001B[0m | \u001B[0m 278.1   \u001B[0m | \u001B[0m 8.551   \u001B[0m | \u001B[0m 333.5   \u001B[0m | \u001B[0m 19.41   \u001B[0m |\n",
      "| \u001B[0m 8       \u001B[0m | \u001B[0m 0.7653  \u001B[0m | \u001B[0m 261.5   \u001B[0m | \u001B[0m 12.68   \u001B[0m | \u001B[0m 172.4   \u001B[0m | \u001B[0m 72.84   \u001B[0m |\n",
      "| \u001B[0m 9       \u001B[0m | \u001B[0m 0.7657  \u001B[0m | \u001B[0m 52.4    \u001B[0m | \u001B[0m 6.53    \u001B[0m | \u001B[0m 407.1   \u001B[0m | \u001B[0m 98.1    \u001B[0m |\n",
      "| \u001B[0m 10      \u001B[0m | \u001B[0m 0.7664  \u001B[0m | \u001B[0m 196.8   \u001B[0m | \u001B[0m 10.08   \u001B[0m | \u001B[0m 458.0   \u001B[0m | \u001B[0m 65.63   \u001B[0m |\n",
      "=========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'target': 0.7705098101131143,\n 'params': {'border_count': 185.37344797295015,\n  'depth': 6.405537966108271,\n  'l2_leaf_reg': 290.55373136202036,\n  'max_leaves': 65.69970433836252}}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.051177,
     "end_time": "2020-11-23T16:52:31.451640",
     "exception": false,
     "start_time": "2020-11-23T16:52:31.400463",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "cellId": "ba4wdwyypnjxlgzfd769b9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!M\n",
    "user_sum_dict = train_user_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "user_count_dict = train_user_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "content_sum_dict = train_content_agg['sum'].astype('int32').to_dict(defaultdict(int))\n",
    "content_count_dict = train_content_agg['count'].astype('int32').to_dict(defaultdict(int))\n",
    "\n",
    "for filename, dic in zip([\"user_sum_dict\", \"user_count_dict\", \"content_sum_dict\", \"content_count_dict\"],\n",
    "                         [user_sum_dict, user_count_dict, content_sum_dict, content_count_dict]):\n",
    "    with open(f'{kaggle_path}/{filename}.pickle', 'wb') as handle:\n",
    "        pickle.dump(dic, handle)\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.618845,
     "end_time": "2020-11-23T16:52:32.122494",
     "exception": false,
     "start_time": "2020-11-23T16:52:31.503649",
     "status": "completed"
    },
    "tags": [],
    "cellId": "7ui7ur3vc7044m7d88w7h2",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.head()\n",
    "del train_df\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "cellId": "t8443l740slicr5x1cuvl"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "validaten_flg = True\n",
    "if validaten_flg:\n",
    "    from emulator import Iter_Valid\n",
    "    iter_test = Iter_Valid(test_df,max_user=1000)\n",
    "    predicted = []\n",
    "    def set_predict(df):\n",
    "        predicted.append(df)\n",
    "else:\n",
    "    import riiideducation\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict"
   ],
   "metadata": {
    "cellId": "6qrpfrl3bhn281e5c5twea"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# cumcount = sum([len(df) for df in predicted])\n",
    "# count = 0\n",
    "# pbar = tqdm(total=cumcount)\n",
    "# previous_test_df = None\n",
    "# for (current_test, current_prediction_df) in iter_test:\n",
    "#     count+=1\n",
    "#     if previous_test_df is not None:\n",
    "#         answers = eval(current_test[\"prior_group_answers_correct\"].iloc[0])\n",
    "#         responses = eval(current_test[\"prior_group_responses\"].iloc[0])\n",
    "#         previous_test_df['answered_correctly'] = answers\n",
    "#         previous_test_df['user_answer'] = responses\n",
    "#         # your feature extraction and model training code here\n",
    "#     previous_test_df = current_test.copy()\n",
    "#     current_test = current_test[current_test.content_type_id == 0]\n",
    "#     # your prediction code here\n",
    "#     current_test['answered_correctly'] = model.predict(current_test[features])  # 0.5\n",
    "#     set_predict(current_test.loc[:,['row_id', 'answered_correctly']])\n",
    "#     pbar.update(len(current_test))\n",
    "# print(f\"count {count} {len(predicted)}\")"
   ],
   "metadata": {
    "papermill": {
     "duration": 466.435487,
     "end_time": "2020-11-13T14:06:20.068150",
     "exception": false,
     "start_time": "2020-11-13T13:58:33.632663",
     "status": "completed"
    },
    "tags": [],
    "cellId": "hkq3ce6f9zot3ymxi9x1s"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "valid_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "cellId": "yzork8xo17phg263eq5lvj"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "prior_test_df = None\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    if prior_test_df is not None:\n",
    "        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop = True)\n",
    "        \n",
    "        user_ids = prior_test_df['user_id'].values\n",
    "        content_ids = prior_test_df['content_id'].values\n",
    "        targets = prior_test_df[target].values\n",
    "\n",
    "        # for user_id, content_id, answered_correctly in prior_test_df[[\"user_id\", \"content_id\", target]].values:\n",
    "        for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n",
    "            user_sum_dict[user_id] += answered_correctly\n",
    "            user_count_dict[user_id] += 1\n",
    "            content_sum_dict[content_id] += answered_correctly\n",
    "            content_count_dict[content_id] += 1\n",
    "\n",
    "    prior_test_df = test_df.copy()\n",
    "    \n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n",
    "    test_df.drop(labels=\"part\", axis=1, inplace=True)\n",
    "    test_df.content_id = test_df.content_id.astype(int)\n",
    "    \n",
    "    test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')    \n",
    "    user_sum = np.zeros(len(test_df), dtype = np.int32)\n",
    "    user_count = np.zeros(len(test_df), dtype = np.int32)\n",
    "    content_sum = np.zeros(len(test_df), dtype = np.int32)\n",
    "    content_count = np.zeros(len(test_df), dtype = np.int32)\n",
    "    \n",
    "    for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n",
    "        user_sum[i] = user_sum_dict[user_id]\n",
    "        user_count[i] = user_count_dict[user_id]\n",
    "        content_sum[i] = content_sum_dict[content_id]\n",
    "        content_count[i] = content_count_dict[content_id]\n",
    "\n",
    "    test_df['user_correctness'] = user_sum / user_count\n",
    "    test_df['content_count'] = content_count\n",
    "    test_df['content_id'] = content_sum / content_count\n",
    "    test_df[target] = model.predict_proba(test_df[features])[:,1]\n",
    "    set_predict(test_df[['row_id', target]])"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.550421,
     "end_time": "2020-11-23T16:52:32.842277",
     "exception": false,
     "start_time": "2020-11-23T16:52:32.291856",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "ikplh5uhkz9cgxru9hxh"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}